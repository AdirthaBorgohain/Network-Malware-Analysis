{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'aws/'\n",
    "JOBLIB_DIR = 'joblibs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(DATA_DIR + 'data1.csv',low_memory=False)\n",
    "df2 = pd.read_csv(DATA_DIR + 'data2.csv', low_memory=False)\n",
    "df3 = pd.read_csv(DATA_DIR + 'data3.csv', low_memory=False)\n",
    "# df4 = pd.read_csv(DATA_DIR + 'data4.csv', low_memory=False)\n",
    "df5 = pd.read_csv(DATA_DIR + 'data5.csv', low_memory=False)\n",
    "df6 = pd.read_csv(DATA_DIR + 'data6.csv', low_memory=False)\n",
    "df7 = pd.read_csv(DATA_DIR + 'data7.csv', low_memory=False)\n",
    "df8 = pd.read_csv(DATA_DIR + 'data8.csv', low_memory=False)\n",
    "df9 = pd.read_csv(DATA_DIR + 'data9.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(['Timestamp'], inplace=True, axis=1)\n",
    "df2.drop(['Timestamp'], inplace=True, axis=1)\n",
    "df3.drop(['Timestamp'], inplace=True, axis=1)\n",
    "# df4.drop(['Timestamp'], inplace=True, axis=1)\n",
    "df5.drop(['Timestamp'], inplace=True, axis=1)\n",
    "df6.drop(['Timestamp'], inplace=True, axis=1)\n",
    "df7.drop(['Timestamp'], inplace=True, axis=1)\n",
    "df8.drop(['Timestamp'], inplace=True, axis=1)\n",
    "df9.drop(['Timestamp'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove all duplicate rows\n",
    "df1.drop_duplicates(inplace=True)\n",
    "df2.drop_duplicates(inplace=True)\n",
    "df3.drop_duplicates(inplace=True)\n",
    "# df4.drop_duplicates(inplace=True)\n",
    "df5.drop_duplicates(inplace=True)\n",
    "df6.drop_duplicates(inplace=True)\n",
    "df7.drop_duplicates(inplace=True)\n",
    "df8.drop_duplicates(inplace=True)\n",
    "df9.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(823732, 79)\n",
      "(591901, 79)\n",
      "(910662, 79)\n",
      "(884658, 79)\n",
      "(906926, 79)\n",
      "(674815, 79)\n",
      "(561405, 79)\n",
      "(518171, 79)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "# print(df4.shape)\n",
    "print(df5.shape)\n",
    "print(df6.shape)\n",
    "print(df7.shape)\n",
    "print(df8.shape)\n",
    "print(df9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df1, df2, df3, df5, df6, df7, df8])\n",
    "del df1\n",
    "del df2\n",
    "del df3\n",
    "del df5\n",
    "del df6\n",
    "del df7\n",
    "del df8\n",
    "del df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign                      4717419\n",
       "DDOS attack-HOIC             198861\n",
       "DoS attacks-Hulk             145199\n",
       "Bot                          144535\n",
       "SSH-Bruteforce                94048\n",
       "DoS attacks-GoldenEye         41406\n",
       "DoS attacks-Slowloris          9908\n",
       "DDOS attack-LOIC-UDP           1730\n",
       "Brute Force -Web                570\n",
       "Brute Force -XSS                229\n",
       "SQL Injection                    85\n",
       "DoS attacks-SlowHTTPTest         55\n",
       "FTP-BruteForce                   54\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Distribution of the different labels present in the data\n",
    "df_final['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benign',\n",
       " 'Bot',\n",
       " 'DoS attacks-SlowHTTPTest',\n",
       " 'DoS attacks-Hulk',\n",
       " 'Brute Force -Web',\n",
       " 'Brute Force -XSS',\n",
       " 'SQL Injection',\n",
       " 'DoS attacks-GoldenEye',\n",
       " 'DoS attacks-Slowloris',\n",
       " 'FTP-BruteForce',\n",
       " 'SSH-Bruteforce',\n",
       " 'DDOS attack-LOIC-UDP',\n",
       " 'DDOS attack-HOIC']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(df_final.Label.unique())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bot', 'DoS attacks-SlowHTTPTest', 'DoS attacks-Hulk', 'Brute Force -Web', 'Brute Force -XSS', 'SQL Injection', 'DoS attacks-GoldenEye', 'DoS attacks-Slowloris', 'FTP-BruteForce', 'SSH-Bruteforce', 'DDOS attack-LOIC-UDP', 'DDOS attack-HOIC']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          Benign\n",
       "1          Benign\n",
       "2          Benign\n",
       "3          Benign\n",
       "4          Benign\n",
       "            ...  \n",
       "1048570    Benign\n",
       "1048571    Benign\n",
       "1048572    Benign\n",
       "1048573    Benign\n",
       "1048574    Benign\n",
       "Name: Label, Length: 5354099, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.remove('Benign')\n",
    "print(labels)\n",
    "\n",
    "df_final['Label'] = df_final['Label'].replace(labels, 'Malware')\n",
    "df_final['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign     4717419\n",
       "Malware     636680\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_df = df_final.loc[df_final['Label'] == 'Malware']\n",
    "benign_df = df_final.loc[df_final['Label'] == 'Benign'].sample(n=800000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([malware_df, benign_df])\n",
    "df_final = df_final.sample(frac=1,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benign     800000\n",
       "Malware    636680\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del malware_df\n",
    "del benign_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dedup:  (1436680, 79)\n",
      "After dedup:  (1428799, 79)\n"
     ]
    }
   ],
   "source": [
    "print('Before dedup: ', df_final.shape)\n",
    "df_final.drop_duplicates(inplace=True)\n",
    "print('After dedup: ', df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final = df_final[df_final['Flow Byts/s'] != 'Infinity']\n",
    "df_final['Flow Byts/s'] = pd.to_numeric(df_final['Flow Byts/s'])\n",
    "\n",
    "df_final = df_final[df_final['Flow Pkts/s'] != 'Infinity']\n",
    "df_final['Flow Pkts/s'] = pd.to_numeric(df_final['Flow Pkts/s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27497</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>5019777</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>394</td>\n",
       "      <td>972.0</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123212</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>11078</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>248</td>\n",
       "      <td>935.0</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326143</td>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>16711</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>326</td>\n",
       "      <td>129.0</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>108.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23853</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>14184</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>291</td>\n",
       "      <td>935.0</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610920</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>65963</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595026</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>118163795</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>592</td>\n",
       "      <td>3193.0</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>45.538462</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>201616.0</td>\n",
       "      <td>198001.212441</td>\n",
       "      <td>341624.0</td>\n",
       "      <td>61608.0</td>\n",
       "      <td>58849014.0</td>\n",
       "      <td>21187.747591</td>\n",
       "      <td>58863996.0</td>\n",
       "      <td>58834032.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296042</td>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>11941</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>326</td>\n",
       "      <td>129.0</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>108.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>866855</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>3217527</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>1349</td>\n",
       "      <td>5911.0</td>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>149.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829161</td>\n",
       "      <td>52015</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>985394</td>\n",
       "      <td>445</td>\n",
       "      <td>6</td>\n",
       "      <td>1655628</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>364</td>\n",
       "      <td>582.0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1424373 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dst Port  Protocol  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
       "27497         80         6        5019777             4             4   \n",
       "123212        80         6          11078             3             4   \n",
       "326143      8080         6          16711             3             4   \n",
       "23853         80         6          14184             3             4   \n",
       "610920        80         6          65963             2             0   \n",
       "...          ...       ...            ...           ...           ...   \n",
       "595026       443         6      118163795            13            11   \n",
       "296042      8080         6          11941             3             4   \n",
       "866855       443         6        3217527             9            31   \n",
       "829161     52015         6             45             1             1   \n",
       "985394       445         6        1655628             7             6   \n",
       "\n",
       "        TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n",
       "27497               394            972.0              394                0   \n",
       "123212              248            935.0              248                0   \n",
       "326143              326            129.0              326                0   \n",
       "23853               291            935.0              291                0   \n",
       "610920                0              0.0                0                0   \n",
       "...                 ...              ...              ...              ...   \n",
       "595026              592           3193.0              192                0   \n",
       "296042              326            129.0              326                0   \n",
       "866855             1349           5911.0              485                0   \n",
       "829161                0              0.0                0                0   \n",
       "985394              364            582.0              103                0   \n",
       "\n",
       "        Fwd Pkt Len Mean  ...  Fwd Seg Size Min  Active Mean     Active Std  \\\n",
       "27497          98.500000  ...                32          0.0       0.000000   \n",
       "123212         82.666667  ...                20          0.0       0.000000   \n",
       "326143        108.666667  ...                20          0.0       0.000000   \n",
       "23853          97.000000  ...                20          0.0       0.000000   \n",
       "610920          0.000000  ...                32          0.0       0.000000   \n",
       "...                  ...  ...               ...          ...            ...   \n",
       "595026         45.538462  ...                20     201616.0  198001.212441   \n",
       "296042        108.666667  ...                20          0.0       0.000000   \n",
       "866855        149.888889  ...                20          0.0       0.000000   \n",
       "829161          0.000000  ...                20          0.0       0.000000   \n",
       "985394         52.000000  ...                20          0.0       0.000000   \n",
       "\n",
       "        Active Max  Active Min   Idle Mean      Idle Std    Idle Max  \\\n",
       "27497          0.0         0.0         0.0      0.000000         0.0   \n",
       "123212         0.0         0.0         0.0      0.000000         0.0   \n",
       "326143         0.0         0.0         0.0      0.000000         0.0   \n",
       "23853          0.0         0.0         0.0      0.000000         0.0   \n",
       "610920         0.0         0.0         0.0      0.000000         0.0   \n",
       "...            ...         ...         ...           ...         ...   \n",
       "595026    341624.0     61608.0  58849014.0  21187.747591  58863996.0   \n",
       "296042         0.0         0.0         0.0      0.000000         0.0   \n",
       "866855         0.0         0.0         0.0      0.000000         0.0   \n",
       "829161         0.0         0.0         0.0      0.000000         0.0   \n",
       "985394         0.0         0.0         0.0      0.000000         0.0   \n",
       "\n",
       "          Idle Min    Label  \n",
       "27497          0.0  Malware  \n",
       "123212         0.0  Malware  \n",
       "326143         0.0  Malware  \n",
       "23853          0.0  Malware  \n",
       "610920         0.0  Malware  \n",
       "...            ...      ...  \n",
       "595026  58834032.0   Benign  \n",
       "296042         0.0  Malware  \n",
       "866855         0.0   Benign  \n",
       "829161         0.0   Benign  \n",
       "985394         0.0   Benign  \n",
       "\n",
       "[1424373 rows x 79 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Act Data Pkts</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27497</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>5019777</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>394</td>\n",
       "      <td>972.0</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123212</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>11078</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>248</td>\n",
       "      <td>935.0</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>82.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326143</td>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>16711</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>326</td>\n",
       "      <td>129.0</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>108.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23853</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>14184</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>291</td>\n",
       "      <td>935.0</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610920</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>65963</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595026</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>118163795</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>592</td>\n",
       "      <td>3193.0</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>45.538462</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>201616.0</td>\n",
       "      <td>198001.212441</td>\n",
       "      <td>341624.0</td>\n",
       "      <td>61608.0</td>\n",
       "      <td>58849014.0</td>\n",
       "      <td>21187.747591</td>\n",
       "      <td>58863996.0</td>\n",
       "      <td>58834032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296042</td>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>11941</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>326</td>\n",
       "      <td>129.0</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>108.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>866855</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>3217527</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>1349</td>\n",
       "      <td>5911.0</td>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>149.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829161</td>\n",
       "      <td>52015</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>985394</td>\n",
       "      <td>445</td>\n",
       "      <td>6</td>\n",
       "      <td>1655628</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>364</td>\n",
       "      <td>582.0</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1424373 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dst Port  Protocol  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
       "27497         80         6        5019777             4             4   \n",
       "123212        80         6          11078             3             4   \n",
       "326143      8080         6          16711             3             4   \n",
       "23853         80         6          14184             3             4   \n",
       "610920        80         6          65963             2             0   \n",
       "...          ...       ...            ...           ...           ...   \n",
       "595026       443         6      118163795            13            11   \n",
       "296042      8080         6          11941             3             4   \n",
       "866855       443         6        3217527             9            31   \n",
       "829161     52015         6             45             1             1   \n",
       "985394       445         6        1655628             7             6   \n",
       "\n",
       "        TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n",
       "27497               394            972.0              394                0   \n",
       "123212              248            935.0              248                0   \n",
       "326143              326            129.0              326                0   \n",
       "23853               291            935.0              291                0   \n",
       "610920                0              0.0                0                0   \n",
       "...                 ...              ...              ...              ...   \n",
       "595026              592           3193.0              192                0   \n",
       "296042              326            129.0              326                0   \n",
       "866855             1349           5911.0              485                0   \n",
       "829161                0              0.0                0                0   \n",
       "985394              364            582.0              103                0   \n",
       "\n",
       "        Fwd Pkt Len Mean  ...  Fwd Act Data Pkts  Fwd Seg Size Min  \\\n",
       "27497          98.500000  ...                  1                32   \n",
       "123212         82.666667  ...                  1                20   \n",
       "326143        108.666667  ...                  1                20   \n",
       "23853          97.000000  ...                  1                20   \n",
       "610920          0.000000  ...                  0                32   \n",
       "...                  ...  ...                ...               ...   \n",
       "595026         45.538462  ...                  6                20   \n",
       "296042        108.666667  ...                  1                20   \n",
       "866855        149.888889  ...                  4                20   \n",
       "829161          0.000000  ...                  0                20   \n",
       "985394         52.000000  ...                  4                20   \n",
       "\n",
       "        Active Mean     Active Std  Active Max  Active Min   Idle Mean  \\\n",
       "27497           0.0       0.000000         0.0         0.0         0.0   \n",
       "123212          0.0       0.000000         0.0         0.0         0.0   \n",
       "326143          0.0       0.000000         0.0         0.0         0.0   \n",
       "23853           0.0       0.000000         0.0         0.0         0.0   \n",
       "610920          0.0       0.000000         0.0         0.0         0.0   \n",
       "...             ...            ...         ...         ...         ...   \n",
       "595026     201616.0  198001.212441    341624.0     61608.0  58849014.0   \n",
       "296042          0.0       0.000000         0.0         0.0         0.0   \n",
       "866855          0.0       0.000000         0.0         0.0         0.0   \n",
       "829161          0.0       0.000000         0.0         0.0         0.0   \n",
       "985394          0.0       0.000000         0.0         0.0         0.0   \n",
       "\n",
       "            Idle Std    Idle Max    Idle Min  \n",
       "27497       0.000000         0.0         0.0  \n",
       "123212      0.000000         0.0         0.0  \n",
       "326143      0.000000         0.0         0.0  \n",
       "23853       0.000000         0.0         0.0  \n",
       "610920      0.000000         0.0         0.0  \n",
       "...              ...         ...         ...  \n",
       "595026  21187.747591  58863996.0  58834032.0  \n",
       "296042      0.000000         0.0         0.0  \n",
       "866855      0.000000         0.0         0.0  \n",
       "829161      0.000000         0.0         0.0  \n",
       "985394      0.000000         0.0         0.0  \n",
       "\n",
       "[1424373 rows x 78 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_final.iloc[:, :78]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27497     Malware\n",
       "123212    Malware\n",
       "326143    Malware\n",
       "23853     Malware\n",
       "610920    Malware\n",
       "           ...   \n",
       "595026     Benign\n",
       "296042    Malware\n",
       "866855     Benign\n",
       "829161     Benign\n",
       "985394     Benign\n",
       "Name: Label, Length: 1424373, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_final['Label']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fwd Seg Size Min',\n",
       " 'Dst Port',\n",
       " 'Bwd Pkt Len Max',\n",
       " 'Init Bwd Win Byts',\n",
       " 'PSH Flag Cnt',\n",
       " 'Init Fwd Win Byts',\n",
       " 'RST Flag Cnt',\n",
       " 'Bwd Pkt Len Std',\n",
       " 'Pkt Len Max',\n",
       " 'Flow IAT Mean',\n",
       " 'Protocol',\n",
       " 'ECE Flag Cnt',\n",
       " 'Bwd Seg Size Avg',\n",
       " 'Pkt Size Avg',\n",
       " 'Fwd IAT Mean',\n",
       " 'Fwd Pkt Len Max',\n",
       " 'ACK Flag Cnt',\n",
       " 'Bwd Pkt Len Min',\n",
       " 'Fwd Seg Size Avg',\n",
       " 'Bwd Pkt Len Mean',\n",
       " 'Bwd IAT Tot',\n",
       " 'Fwd Pkt Len Mean',\n",
       " 'Pkt Len Min',\n",
       " 'TotLen Fwd Pkts',\n",
       " 'Pkt Len Var',\n",
       " 'Fwd Pkt Len Min',\n",
       " 'Pkt Len Mean',\n",
       " 'Subflow Fwd Byts',\n",
       " 'Fwd Pkts/s',\n",
       " 'Fwd Header Len',\n",
       " 'Flow Pkts/s',\n",
       " 'Bwd Pkts/s',\n",
       " 'Subflow Bwd Byts',\n",
       " 'TotLen Bwd Pkts',\n",
       " 'Fwd Pkt Len Std',\n",
       " 'Idle Min',\n",
       " 'Bwd IAT Max',\n",
       " 'Fwd IAT Tot',\n",
       " 'Pkt Len Std',\n",
       " 'Down/Up Ratio',\n",
       " 'Bwd IAT Std',\n",
       " 'Fwd IAT Max',\n",
       " 'Tot Fwd Pkts',\n",
       " 'Flow Duration',\n",
       " 'Flow IAT Max',\n",
       " 'Bwd IAT Min',\n",
       " 'Subflow Fwd Pkts',\n",
       " 'Bwd Header Len',\n",
       " 'Flow Byts/s',\n",
       " 'Bwd IAT Mean',\n",
       " 'Tot Bwd Pkts',\n",
       " 'Subflow Bwd Pkts',\n",
       " 'Fwd IAT Std',\n",
       " 'Fwd IAT Min',\n",
       " 'Flow IAT Std',\n",
       " 'SYN Flag Cnt',\n",
       " 'Fwd PSH Flags',\n",
       " 'Fwd Act Data Pkts',\n",
       " 'URG Flag Cnt',\n",
       " 'Flow IAT Min',\n",
       " 'Active Max',\n",
       " 'Active Mean',\n",
       " 'FIN Flag Cnt',\n",
       " 'Active Std',\n",
       " 'Active Min',\n",
       " 'Idle Mean',\n",
       " 'Idle Max',\n",
       " 'Idle Std']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = joblib.load(JOBLIB_DIR + 'col_rank.joblib')\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = joblib.load(JOBLIB_DIR + 'label_encoder.joblib')\n",
    "y = le.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns\n",
    "\n",
    "scalar = joblib.load(JOBLIB_DIR + 'scaler.joblib')\n",
    "X = scalar.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Act Data Pkts</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.528276</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>-0.007749</td>\n",
       "      <td>-0.034476</td>\n",
       "      <td>-0.016789</td>\n",
       "      <td>-0.034881</td>\n",
       "      <td>-0.012808</td>\n",
       "      <td>0.261794</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>0.376317</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034291</td>\n",
       "      <td>1.401294</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>-0.061411</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>-0.064246</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.528276</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>-0.016303</td>\n",
       "      <td>-0.034714</td>\n",
       "      <td>-0.016789</td>\n",
       "      <td>-0.035959</td>\n",
       "      <td>-0.012947</td>\n",
       "      <td>-0.186130</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>0.137230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034291</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>-0.061411</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>-0.064246</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.113877</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>-0.016293</td>\n",
       "      <td>-0.034714</td>\n",
       "      <td>-0.016789</td>\n",
       "      <td>-0.035383</td>\n",
       "      <td>-0.015969</td>\n",
       "      <td>0.053172</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>0.529835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034291</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>-0.061411</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>-0.064246</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.528276</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>-0.016297</td>\n",
       "      <td>-0.034714</td>\n",
       "      <td>-0.016789</td>\n",
       "      <td>-0.035641</td>\n",
       "      <td>-0.012947</td>\n",
       "      <td>-0.054207</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>0.353666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034291</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>-0.061411</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>-0.064246</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.528276</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>-0.016209</td>\n",
       "      <td>-0.034952</td>\n",
       "      <td>-0.037792</td>\n",
       "      <td>-0.037790</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>-0.946986</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>-1.111052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034529</td>\n",
       "      <td>1.401294</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>-0.061411</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>-0.064246</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424368</td>\n",
       "      <td>-0.509472</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>0.185481</td>\n",
       "      <td>-0.032336</td>\n",
       "      <td>0.019966</td>\n",
       "      <td>-0.033419</td>\n",
       "      <td>-0.004480</td>\n",
       "      <td>-0.357936</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>-0.423413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033102</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>0.133515</td>\n",
       "      <td>0.326535</td>\n",
       "      <td>0.179723</td>\n",
       "      <td>0.010083</td>\n",
       "      <td>0.130992</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>0.045914</td>\n",
       "      <td>3.094026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424369</td>\n",
       "      <td>-0.113877</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>-0.016301</td>\n",
       "      <td>-0.034714</td>\n",
       "      <td>-0.016789</td>\n",
       "      <td>-0.035383</td>\n",
       "      <td>-0.015969</td>\n",
       "      <td>0.053172</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>0.529835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034291</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>-0.061411</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>-0.064246</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424370</td>\n",
       "      <td>-0.509472</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>-0.010827</td>\n",
       "      <td>-0.033287</td>\n",
       "      <td>0.124979</td>\n",
       "      <td>-0.027829</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.540979</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>1.152299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033578</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>-0.061411</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>-0.064246</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424371</td>\n",
       "      <td>2.161953</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>-0.016322</td>\n",
       "      <td>-0.035190</td>\n",
       "      <td>-0.032541</td>\n",
       "      <td>-0.037790</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>-0.946986</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>-1.111052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034529</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>-0.061411</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>-0.064246</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424372</td>\n",
       "      <td>-0.509369</td>\n",
       "      <td>-0.337506</td>\n",
       "      <td>-0.013494</td>\n",
       "      <td>-0.033763</td>\n",
       "      <td>-0.006288</td>\n",
       "      <td>-0.035102</td>\n",
       "      <td>-0.014271</td>\n",
       "      <td>-0.630985</td>\n",
       "      <td>-0.266804</td>\n",
       "      <td>-0.325842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033578</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.075637</td>\n",
       "      <td>-0.061411</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>-0.064246</td>\n",
       "      <td>-0.011673</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1424373 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Dst Port  Protocol  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  \\\n",
       "0       -0.528276 -0.337506      -0.007749     -0.034476     -0.016789   \n",
       "1       -0.528276 -0.337506      -0.016303     -0.034714     -0.016789   \n",
       "2       -0.113877 -0.337506      -0.016293     -0.034714     -0.016789   \n",
       "3       -0.528276 -0.337506      -0.016297     -0.034714     -0.016789   \n",
       "4       -0.528276 -0.337506      -0.016209     -0.034952     -0.037792   \n",
       "...           ...       ...            ...           ...           ...   \n",
       "1424368 -0.509472 -0.337506       0.185481     -0.032336      0.019966   \n",
       "1424369 -0.113877 -0.337506      -0.016301     -0.034714     -0.016789   \n",
       "1424370 -0.509472 -0.337506      -0.010827     -0.033287      0.124979   \n",
       "1424371  2.161953 -0.337506      -0.016322     -0.035190     -0.032541   \n",
       "1424372 -0.509369 -0.337506      -0.013494     -0.033763     -0.006288   \n",
       "\n",
       "         TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  \\\n",
       "0              -0.034881        -0.012808         0.261794        -0.266804   \n",
       "1              -0.035959        -0.012947        -0.186130        -0.266804   \n",
       "2              -0.035383        -0.015969         0.053172        -0.266804   \n",
       "3              -0.035641        -0.012947        -0.054207        -0.266804   \n",
       "4              -0.037790        -0.016453        -0.946986        -0.266804   \n",
       "...                  ...              ...              ...              ...   \n",
       "1424368        -0.033419        -0.004480        -0.357936        -0.266804   \n",
       "1424369        -0.035383        -0.015969         0.053172        -0.266804   \n",
       "1424370        -0.027829         0.005712         0.540979        -0.266804   \n",
       "1424371        -0.037790        -0.016453        -0.946986        -0.266804   \n",
       "1424372        -0.035102        -0.014271        -0.630985        -0.266804   \n",
       "\n",
       "         Fwd Pkt Len Mean  ...  Fwd Act Data Pkts  Fwd Seg Size Min  \\\n",
       "0                0.376317  ...          -0.034291          1.401294   \n",
       "1                0.137230  ...          -0.034291         -0.210802   \n",
       "2                0.529835  ...          -0.034291         -0.210802   \n",
       "3                0.353666  ...          -0.034291         -0.210802   \n",
       "4               -1.111052  ...          -0.034529          1.401294   \n",
       "...                   ...  ...                ...               ...   \n",
       "1424368         -0.423413  ...          -0.033102         -0.210802   \n",
       "1424369          0.529835  ...          -0.034291         -0.210802   \n",
       "1424370          1.152299  ...          -0.033578         -0.210802   \n",
       "1424371         -1.111052  ...          -0.034529         -0.210802   \n",
       "1424372         -0.325842  ...          -0.033578         -0.210802   \n",
       "\n",
       "         Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n",
       "0          -0.075637   -0.061411   -0.088853   -0.064246  -0.011673 -0.001722   \n",
       "1          -0.075637   -0.061411   -0.088853   -0.064246  -0.011673 -0.001722   \n",
       "2          -0.075637   -0.061411   -0.088853   -0.064246  -0.011673 -0.001722   \n",
       "3          -0.075637   -0.061411   -0.088853   -0.064246  -0.011673 -0.001722   \n",
       "4          -0.075637   -0.061411   -0.088853   -0.064246  -0.011673 -0.001722   \n",
       "...              ...         ...         ...         ...        ...       ...   \n",
       "1424368     0.133515    0.326535    0.179723    0.010083   0.130992 -0.001647   \n",
       "1424369    -0.075637   -0.061411   -0.088853   -0.064246  -0.011673 -0.001722   \n",
       "1424370    -0.075637   -0.061411   -0.088853   -0.064246  -0.011673 -0.001722   \n",
       "1424371    -0.075637   -0.061411   -0.088853   -0.064246  -0.011673 -0.001722   \n",
       "1424372    -0.075637   -0.061411   -0.088853   -0.064246  -0.011673 -0.001722   \n",
       "\n",
       "         Idle Max  Idle Min  \n",
       "0       -0.005077 -0.237519  \n",
       "1       -0.005077 -0.237519  \n",
       "2       -0.005077 -0.237519  \n",
       "3       -0.005077 -0.237519  \n",
       "4       -0.005077 -0.237519  \n",
       "...           ...       ...  \n",
       "1424368  0.045914  3.094026  \n",
       "1424369 -0.005077 -0.237519  \n",
       "1424370 -0.005077 -0.237519  \n",
       "1424371 -0.005077 -0.237519  \n",
       "1424372 -0.005077 -0.237519  \n",
       "\n",
       "[1424373 rows x 78 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X, columns=columns)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fwd Seg Size Min',\n",
       " 'Dst Port',\n",
       " 'Bwd Pkt Len Max',\n",
       " 'Init Bwd Win Byts',\n",
       " 'PSH Flag Cnt',\n",
       " 'Init Fwd Win Byts',\n",
       " 'RST Flag Cnt',\n",
       " 'Bwd Pkt Len Std',\n",
       " 'Pkt Len Max',\n",
       " 'Flow IAT Mean',\n",
       " 'Protocol',\n",
       " 'ECE Flag Cnt',\n",
       " 'Bwd Seg Size Avg',\n",
       " 'Pkt Size Avg',\n",
       " 'Fwd IAT Mean',\n",
       " 'Fwd Pkt Len Max',\n",
       " 'ACK Flag Cnt',\n",
       " 'Bwd Pkt Len Min',\n",
       " 'Fwd Seg Size Avg',\n",
       " 'Bwd Pkt Len Mean',\n",
       " 'Bwd IAT Tot',\n",
       " 'Fwd Pkt Len Mean',\n",
       " 'Pkt Len Min',\n",
       " 'TotLen Fwd Pkts',\n",
       " 'Pkt Len Var',\n",
       " 'Fwd Pkt Len Min',\n",
       " 'Pkt Len Mean',\n",
       " 'Subflow Fwd Byts',\n",
       " 'Fwd Pkts/s',\n",
       " 'Fwd Header Len',\n",
       " 'Flow Pkts/s',\n",
       " 'Bwd Pkts/s',\n",
       " 'Subflow Bwd Byts',\n",
       " 'TotLen Bwd Pkts',\n",
       " 'Fwd Pkt Len Std',\n",
       " 'Idle Min']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURE_NO = 36\n",
    "\n",
    "sel_cols = cols[:FEATURE_NO]\n",
    "sel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Bwd Pkt Len Max</th>\n",
       "      <th>Init Bwd Win Byts</th>\n",
       "      <th>PSH Flag Cnt</th>\n",
       "      <th>Init Fwd Win Byts</th>\n",
       "      <th>RST Flag Cnt</th>\n",
       "      <th>Bwd Pkt Len Std</th>\n",
       "      <th>Pkt Len Max</th>\n",
       "      <th>Flow IAT Mean</th>\n",
       "      <th>...</th>\n",
       "      <th>Pkt Len Mean</th>\n",
       "      <th>Subflow Fwd Byts</th>\n",
       "      <th>Fwd Pkts/s</th>\n",
       "      <th>Fwd Header Len</th>\n",
       "      <th>Flow Pkts/s</th>\n",
       "      <th>Bwd Pkts/s</th>\n",
       "      <th>Subflow Bwd Byts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.401294</td>\n",
       "      <td>-0.528276</td>\n",
       "      <td>1.102529</td>\n",
       "      <td>-0.371280</td>\n",
       "      <td>0.879863</td>\n",
       "      <td>0.348605</td>\n",
       "      <td>-0.680105</td>\n",
       "      <td>1.494657</td>\n",
       "      <td>0.904042</td>\n",
       "      <td>-0.189990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620174</td>\n",
       "      <td>-0.034881</td>\n",
       "      <td>-0.089937</td>\n",
       "      <td>-0.034608</td>\n",
       "      <td>-0.098282</td>\n",
       "      <td>-0.108859</td>\n",
       "      <td>-0.012808</td>\n",
       "      <td>-0.012808</td>\n",
       "      <td>0.544167</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.528276</td>\n",
       "      <td>1.025083</td>\n",
       "      <td>-0.371280</td>\n",
       "      <td>0.879863</td>\n",
       "      <td>1.948899</td>\n",
       "      <td>1.470362</td>\n",
       "      <td>1.402967</td>\n",
       "      <td>0.828395</td>\n",
       "      <td>-0.236119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579835</td>\n",
       "      <td>-0.035959</td>\n",
       "      <td>-0.088157</td>\n",
       "      <td>-0.036509</td>\n",
       "      <td>-0.094161</td>\n",
       "      <td>-0.080621</td>\n",
       "      <td>-0.012947</td>\n",
       "      <td>-0.012947</td>\n",
       "      <td>0.133322</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.113877</td>\n",
       "      <td>-0.697577</td>\n",
       "      <td>-0.371280</td>\n",
       "      <td>0.879863</td>\n",
       "      <td>-0.425251</td>\n",
       "      <td>1.470362</td>\n",
       "      <td>-0.647584</td>\n",
       "      <td>-0.416717</td>\n",
       "      <td>-0.236058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360734</td>\n",
       "      <td>-0.035383</td>\n",
       "      <td>-0.088759</td>\n",
       "      <td>-0.036509</td>\n",
       "      <td>-0.095554</td>\n",
       "      <td>-0.090160</td>\n",
       "      <td>-0.015969</td>\n",
       "      <td>-0.015969</td>\n",
       "      <td>0.477110</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.528276</td>\n",
       "      <td>1.025083</td>\n",
       "      <td>-0.371280</td>\n",
       "      <td>0.879863</td>\n",
       "      <td>1.948899</td>\n",
       "      <td>1.470362</td>\n",
       "      <td>1.402967</td>\n",
       "      <td>0.828395</td>\n",
       "      <td>-0.236085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635391</td>\n",
       "      <td>-0.035641</td>\n",
       "      <td>-0.088548</td>\n",
       "      <td>-0.036509</td>\n",
       "      <td>-0.095066</td>\n",
       "      <td>-0.086818</td>\n",
       "      <td>-0.012947</td>\n",
       "      <td>-0.012947</td>\n",
       "      <td>0.322846</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.401294</td>\n",
       "      <td>-0.528276</td>\n",
       "      <td>-0.932010</td>\n",
       "      <td>-0.383474</td>\n",
       "      <td>-1.136540</td>\n",
       "      <td>-0.755106</td>\n",
       "      <td>-0.680105</td>\n",
       "      <td>-0.914066</td>\n",
       "      <td>-1.083230</td>\n",
       "      <td>-0.231984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.948590</td>\n",
       "      <td>-0.037790</td>\n",
       "      <td>-0.089743</td>\n",
       "      <td>-0.036746</td>\n",
       "      <td>-0.098094</td>\n",
       "      <td>-0.108921</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>-0.959748</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424368</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.509472</td>\n",
       "      <td>2.061190</td>\n",
       "      <td>-0.373663</td>\n",
       "      <td>0.879863</td>\n",
       "      <td>-0.425251</td>\n",
       "      <td>-0.680105</td>\n",
       "      <td>1.730695</td>\n",
       "      <td>1.840432</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616269</td>\n",
       "      <td>-0.033419</td>\n",
       "      <td>-0.089942</td>\n",
       "      <td>-0.030568</td>\n",
       "      <td>-0.098291</td>\n",
       "      <td>-0.108914</td>\n",
       "      <td>-0.004480</td>\n",
       "      <td>-0.004480</td>\n",
       "      <td>-0.440297</td>\n",
       "      <td>3.094026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424369</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.113877</td>\n",
       "      <td>-0.697577</td>\n",
       "      <td>-0.371280</td>\n",
       "      <td>0.879863</td>\n",
       "      <td>-0.425251</td>\n",
       "      <td>1.470362</td>\n",
       "      <td>-0.647584</td>\n",
       "      <td>-0.416717</td>\n",
       "      <td>-0.236109</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360734</td>\n",
       "      <td>-0.035383</td>\n",
       "      <td>-0.088286</td>\n",
       "      <td>-0.036509</td>\n",
       "      <td>-0.094460</td>\n",
       "      <td>-0.082666</td>\n",
       "      <td>-0.015969</td>\n",
       "      <td>-0.015969</td>\n",
       "      <td>0.477110</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424370</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.509472</td>\n",
       "      <td>2.123985</td>\n",
       "      <td>-0.369229</td>\n",
       "      <td>0.879863</td>\n",
       "      <td>-0.425251</td>\n",
       "      <td>-0.680105</td>\n",
       "      <td>1.290581</td>\n",
       "      <td>1.901768</td>\n",
       "      <td>-0.230917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881625</td>\n",
       "      <td>-0.027829</td>\n",
       "      <td>-0.089924</td>\n",
       "      <td>-0.032944</td>\n",
       "      <td>-0.098211</td>\n",
       "      <td>-0.108166</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>0.614482</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424371</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>2.161953</td>\n",
       "      <td>-0.932010</td>\n",
       "      <td>-0.369340</td>\n",
       "      <td>-1.136540</td>\n",
       "      <td>-0.743182</td>\n",
       "      <td>-0.680105</td>\n",
       "      <td>-0.914066</td>\n",
       "      <td>-1.083230</td>\n",
       "      <td>-0.236235</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.948590</td>\n",
       "      <td>-0.037790</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>-0.038053</td>\n",
       "      <td>0.192268</td>\n",
       "      <td>1.632823</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>-0.959748</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1424372</td>\n",
       "      <td>-0.210802</td>\n",
       "      <td>-0.509369</td>\n",
       "      <td>-0.075913</td>\n",
       "      <td>-0.369118</td>\n",
       "      <td>0.879863</td>\n",
       "      <td>-0.425251</td>\n",
       "      <td>-0.680105</td>\n",
       "      <td>-0.137048</td>\n",
       "      <td>-0.247022</td>\n",
       "      <td>-0.227340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250177</td>\n",
       "      <td>-0.035102</td>\n",
       "      <td>-0.089914</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>-0.098241</td>\n",
       "      <td>-0.108637</td>\n",
       "      <td>-0.014271</td>\n",
       "      <td>-0.014271</td>\n",
       "      <td>-0.584020</td>\n",
       "      <td>-0.237519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1424373 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fwd Seg Size Min  Dst Port  Bwd Pkt Len Max  Init Bwd Win Byts  \\\n",
       "0                1.401294 -0.528276         1.102529          -0.371280   \n",
       "1               -0.210802 -0.528276         1.025083          -0.371280   \n",
       "2               -0.210802 -0.113877        -0.697577          -0.371280   \n",
       "3               -0.210802 -0.528276         1.025083          -0.371280   \n",
       "4                1.401294 -0.528276        -0.932010          -0.383474   \n",
       "...                   ...       ...              ...                ...   \n",
       "1424368         -0.210802 -0.509472         2.061190          -0.373663   \n",
       "1424369         -0.210802 -0.113877        -0.697577          -0.371280   \n",
       "1424370         -0.210802 -0.509472         2.123985          -0.369229   \n",
       "1424371         -0.210802  2.161953        -0.932010          -0.369340   \n",
       "1424372         -0.210802 -0.509369        -0.075913          -0.369118   \n",
       "\n",
       "         PSH Flag Cnt  Init Fwd Win Byts  RST Flag Cnt  Bwd Pkt Len Std  \\\n",
       "0            0.879863           0.348605     -0.680105         1.494657   \n",
       "1            0.879863           1.948899      1.470362         1.402967   \n",
       "2            0.879863          -0.425251      1.470362        -0.647584   \n",
       "3            0.879863           1.948899      1.470362         1.402967   \n",
       "4           -1.136540          -0.755106     -0.680105        -0.914066   \n",
       "...               ...                ...           ...              ...   \n",
       "1424368      0.879863          -0.425251     -0.680105         1.730695   \n",
       "1424369      0.879863          -0.425251      1.470362        -0.647584   \n",
       "1424370      0.879863          -0.425251     -0.680105         1.290581   \n",
       "1424371     -1.136540          -0.743182     -0.680105        -0.914066   \n",
       "1424372      0.879863          -0.425251     -0.680105        -0.137048   \n",
       "\n",
       "         Pkt Len Max  Flow IAT Mean  ...  Pkt Len Mean  Subflow Fwd Byts  \\\n",
       "0           0.904042      -0.189990  ...      0.620174         -0.034881   \n",
       "1           0.828395      -0.236119  ...      0.579835         -0.035959   \n",
       "2          -0.416717      -0.236058  ...     -0.360734         -0.035383   \n",
       "3           0.828395      -0.236085  ...      0.635391         -0.035641   \n",
       "4          -1.083230      -0.231984  ...     -0.948590         -0.037790   \n",
       "...              ...            ...  ...           ...               ...   \n",
       "1424368     1.840432       0.095089  ...      0.616269         -0.033419   \n",
       "1424369    -0.416717      -0.236109  ...     -0.360734         -0.035383   \n",
       "1424370     1.901768      -0.230917  ...      0.881625         -0.027829   \n",
       "1424371    -1.083230      -0.236235  ...     -0.948590         -0.037790   \n",
       "1424372    -0.247022      -0.227340  ...     -0.250177         -0.035102   \n",
       "\n",
       "         Fwd Pkts/s  Fwd Header Len  Flow Pkts/s  Bwd Pkts/s  \\\n",
       "0         -0.089937       -0.034608    -0.098282   -0.108859   \n",
       "1         -0.088157       -0.036509    -0.094161   -0.080621   \n",
       "2         -0.088759       -0.036509    -0.095554   -0.090160   \n",
       "3         -0.088548       -0.036509    -0.095066   -0.086818   \n",
       "4         -0.089743       -0.036746    -0.098094   -0.108921   \n",
       "...             ...             ...          ...         ...   \n",
       "1424368   -0.089942       -0.030568    -0.098291   -0.108914   \n",
       "1424369   -0.088286       -0.036509    -0.094460   -0.082666   \n",
       "1424370   -0.089924       -0.032944    -0.098211   -0.108166   \n",
       "1424371    0.056535       -0.038053     0.192268    1.632823   \n",
       "1424372   -0.089914       -0.034132    -0.098241   -0.108637   \n",
       "\n",
       "         Subflow Bwd Byts  TotLen Bwd Pkts  Fwd Pkt Len Std  Idle Min  \n",
       "0               -0.012808        -0.012808         0.544167 -0.237519  \n",
       "1               -0.012947        -0.012947         0.133322 -0.237519  \n",
       "2               -0.015969        -0.015969         0.477110 -0.237519  \n",
       "3               -0.012947        -0.012947         0.322846 -0.237519  \n",
       "4               -0.016453        -0.016453        -0.959748 -0.237519  \n",
       "...                   ...              ...              ...       ...  \n",
       "1424368         -0.004480        -0.004480        -0.440297  3.094026  \n",
       "1424369         -0.015969        -0.015969         0.477110 -0.237519  \n",
       "1424370          0.005712         0.005712         0.614482 -0.237519  \n",
       "1424371         -0.016453        -0.016453        -0.959748 -0.237519  \n",
       "1424372         -0.014271        -0.014271        -0.584020 -0.237519  \n",
       "\n",
       "[1424373 rows x 36 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[sel_cols]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train (997061, 36)\n",
      "X Test (427312, 36)\n",
      "Y Train (997061,)\n",
      "Y Test (427312,)\n"
     ]
    }
   ],
   "source": [
    "print('X Train', X_train.shape)\n",
    "print('X Test', X_test.shape)\n",
    "print('Y Train', y_train.shape)\n",
    "print('Y Test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Dataset to Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.5, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, tree_method='gpu_hist', verbosity=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# xgbmodel = XGBClassifier(tree_method='gpu_hist', n_jobs=-1, learning_rate=0.5)\n",
    "# xgbmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbmodel = joblib.load(JOBLIB_DIR + 'xgbmodel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(xgbmodel, JOBLIB_DIR + 'xgbmodel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.118239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 2749.1875 Total: 4046.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3955695\ttotal: 174ms\tremaining: 2m 54s\n",
      "1:\tlearn: 0.2007195\ttotal: 360ms\tremaining: 2m 59s\n",
      "2:\tlearn: 0.1183359\ttotal: 561ms\tremaining: 3m 6s\n",
      "3:\tlearn: 0.0762613\ttotal: 770ms\tremaining: 3m 11s\n",
      "4:\tlearn: 0.0489147\ttotal: 985ms\tremaining: 3m 16s\n",
      "5:\tlearn: 0.0365879\ttotal: 1.2s\tremaining: 3m 18s\n",
      "6:\tlearn: 0.0312680\ttotal: 1.39s\tremaining: 3m 17s\n",
      "7:\tlearn: 0.0262952\ttotal: 1.57s\tremaining: 3m 15s\n",
      "8:\tlearn: 0.0188689\ttotal: 1.76s\tremaining: 3m 13s\n",
      "9:\tlearn: 0.0156583\ttotal: 1.95s\tremaining: 3m 12s\n",
      "10:\tlearn: 0.0143584\ttotal: 2.12s\tremaining: 3m 10s\n",
      "11:\tlearn: 0.0126582\ttotal: 2.33s\tremaining: 3m 11s\n",
      "12:\tlearn: 0.0115604\ttotal: 2.5s\tremaining: 3m 9s\n",
      "13:\tlearn: 0.0099272\ttotal: 2.68s\tremaining: 3m 8s\n",
      "14:\tlearn: 0.0094879\ttotal: 2.85s\tremaining: 3m 6s\n",
      "15:\tlearn: 0.0091410\ttotal: 3.01s\tremaining: 3m 5s\n",
      "16:\tlearn: 0.0080991\ttotal: 3.17s\tremaining: 3m 3s\n",
      "17:\tlearn: 0.0074399\ttotal: 3.34s\tremaining: 3m 2s\n",
      "18:\tlearn: 0.0072129\ttotal: 3.48s\tremaining: 2m 59s\n",
      "19:\tlearn: 0.0068198\ttotal: 3.64s\tremaining: 2m 58s\n",
      "20:\tlearn: 0.0065221\ttotal: 3.79s\tremaining: 2m 56s\n",
      "21:\tlearn: 0.0061694\ttotal: 4s\tremaining: 2m 57s\n",
      "22:\tlearn: 0.0056421\ttotal: 4.17s\tremaining: 2m 57s\n",
      "23:\tlearn: 0.0047738\ttotal: 4.33s\tremaining: 2m 55s\n",
      "24:\tlearn: 0.0044400\ttotal: 4.49s\tremaining: 2m 55s\n",
      "25:\tlearn: 0.0041574\ttotal: 4.64s\tremaining: 2m 54s\n",
      "26:\tlearn: 0.0039942\ttotal: 4.82s\tremaining: 2m 53s\n",
      "27:\tlearn: 0.0038717\ttotal: 4.98s\tremaining: 2m 52s\n",
      "28:\tlearn: 0.0037636\ttotal: 5.13s\tremaining: 2m 51s\n",
      "29:\tlearn: 0.0036091\ttotal: 5.33s\tremaining: 2m 52s\n",
      "30:\tlearn: 0.0035100\ttotal: 5.48s\tremaining: 2m 51s\n",
      "31:\tlearn: 0.0034400\ttotal: 5.62s\tremaining: 2m 50s\n",
      "32:\tlearn: 0.0032601\ttotal: 5.77s\tremaining: 2m 49s\n",
      "33:\tlearn: 0.0031867\ttotal: 6s\tremaining: 2m 50s\n",
      "34:\tlearn: 0.0030414\ttotal: 6.32s\tremaining: 2m 54s\n",
      "35:\tlearn: 0.0029257\ttotal: 6.49s\tremaining: 2m 53s\n",
      "36:\tlearn: 0.0027769\ttotal: 6.67s\tremaining: 2m 53s\n",
      "37:\tlearn: 0.0025785\ttotal: 6.83s\tremaining: 2m 53s\n",
      "38:\tlearn: 0.0025264\ttotal: 7s\tremaining: 2m 52s\n",
      "39:\tlearn: 0.0024606\ttotal: 7.13s\tremaining: 2m 51s\n",
      "40:\tlearn: 0.0023962\ttotal: 7.3s\tremaining: 2m 50s\n",
      "41:\tlearn: 0.0023581\ttotal: 7.46s\tremaining: 2m 50s\n",
      "42:\tlearn: 0.0023336\ttotal: 7.63s\tremaining: 2m 49s\n",
      "43:\tlearn: 0.0022453\ttotal: 7.8s\tremaining: 2m 49s\n",
      "44:\tlearn: 0.0022257\ttotal: 7.96s\tremaining: 2m 48s\n",
      "45:\tlearn: 0.0022028\ttotal: 8.12s\tremaining: 2m 48s\n",
      "46:\tlearn: 0.0019612\ttotal: 8.29s\tremaining: 2m 48s\n",
      "47:\tlearn: 0.0019449\ttotal: 8.43s\tremaining: 2m 47s\n",
      "48:\tlearn: 0.0019285\ttotal: 8.58s\tremaining: 2m 46s\n",
      "49:\tlearn: 0.0018905\ttotal: 8.74s\tremaining: 2m 46s\n",
      "50:\tlearn: 0.0018815\ttotal: 8.88s\tremaining: 2m 45s\n",
      "51:\tlearn: 0.0018643\ttotal: 9.03s\tremaining: 2m 44s\n",
      "52:\tlearn: 0.0018556\ttotal: 9.19s\tremaining: 2m 44s\n",
      "53:\tlearn: 0.0018327\ttotal: 9.33s\tremaining: 2m 43s\n",
      "54:\tlearn: 0.0018185\ttotal: 9.49s\tremaining: 2m 42s\n",
      "55:\tlearn: 0.0018035\ttotal: 9.63s\tremaining: 2m 42s\n",
      "56:\tlearn: 0.0017904\ttotal: 9.79s\tremaining: 2m 42s\n",
      "57:\tlearn: 0.0017718\ttotal: 9.94s\tremaining: 2m 41s\n",
      "58:\tlearn: 0.0017052\ttotal: 10.1s\tremaining: 2m 41s\n",
      "59:\tlearn: 0.0016772\ttotal: 10.3s\tremaining: 2m 40s\n",
      "60:\tlearn: 0.0016589\ttotal: 10.4s\tremaining: 2m 40s\n",
      "61:\tlearn: 0.0016186\ttotal: 10.6s\tremaining: 2m 39s\n",
      "62:\tlearn: 0.0016054\ttotal: 10.7s\tremaining: 2m 39s\n",
      "63:\tlearn: 0.0016018\ttotal: 10.9s\tremaining: 2m 38s\n",
      "64:\tlearn: 0.0015943\ttotal: 11s\tremaining: 2m 38s\n",
      "65:\tlearn: 0.0015909\ttotal: 11.2s\tremaining: 2m 37s\n",
      "66:\tlearn: 0.0015857\ttotal: 11.3s\tremaining: 2m 37s\n",
      "67:\tlearn: 0.0015525\ttotal: 11.5s\tremaining: 2m 37s\n",
      "68:\tlearn: 0.0015466\ttotal: 11.6s\tremaining: 2m 36s\n",
      "69:\tlearn: 0.0015398\ttotal: 11.8s\tremaining: 2m 36s\n",
      "70:\tlearn: 0.0015227\ttotal: 11.9s\tremaining: 2m 36s\n",
      "71:\tlearn: 0.0015012\ttotal: 12.1s\tremaining: 2m 35s\n",
      "72:\tlearn: 0.0014741\ttotal: 12.2s\tremaining: 2m 35s\n",
      "73:\tlearn: 0.0014659\ttotal: 12.4s\tremaining: 2m 34s\n",
      "74:\tlearn: 0.0014566\ttotal: 12.5s\tremaining: 2m 34s\n",
      "75:\tlearn: 0.0014248\ttotal: 12.7s\tremaining: 2m 34s\n",
      "76:\tlearn: 0.0014241\ttotal: 12.8s\tremaining: 2m 33s\n",
      "77:\tlearn: 0.0014207\ttotal: 13s\tremaining: 2m 33s\n",
      "78:\tlearn: 0.0013991\ttotal: 13.1s\tremaining: 2m 32s\n",
      "79:\tlearn: 0.0013985\ttotal: 13.2s\tremaining: 2m 32s\n",
      "80:\tlearn: 0.0013895\ttotal: 13.4s\tremaining: 2m 32s\n",
      "81:\tlearn: 0.0013228\ttotal: 13.6s\tremaining: 2m 31s\n",
      "82:\tlearn: 0.0012978\ttotal: 13.7s\tremaining: 2m 31s\n",
      "83:\tlearn: 0.0012807\ttotal: 13.9s\tremaining: 2m 31s\n",
      "84:\tlearn: 0.0012794\ttotal: 14s\tremaining: 2m 31s\n",
      "85:\tlearn: 0.0012390\ttotal: 14.2s\tremaining: 2m 30s\n",
      "86:\tlearn: 0.0011934\ttotal: 14.4s\tremaining: 2m 30s\n",
      "87:\tlearn: 0.0011898\ttotal: 14.5s\tremaining: 2m 30s\n",
      "88:\tlearn: 0.0011893\ttotal: 14.6s\tremaining: 2m 29s\n",
      "89:\tlearn: 0.0011281\ttotal: 14.8s\tremaining: 2m 29s\n",
      "90:\tlearn: 0.0011082\ttotal: 15s\tremaining: 2m 29s\n",
      "91:\tlearn: 0.0011078\ttotal: 15.1s\tremaining: 2m 29s\n",
      "92:\tlearn: 0.0010974\ttotal: 15.3s\tremaining: 2m 28s\n",
      "93:\tlearn: 0.0010967\ttotal: 15.4s\tremaining: 2m 28s\n",
      "94:\tlearn: 0.0010667\ttotal: 15.6s\tremaining: 2m 28s\n",
      "95:\tlearn: 0.0010596\ttotal: 15.7s\tremaining: 2m 27s\n",
      "96:\tlearn: 0.0010593\ttotal: 15.9s\tremaining: 2m 27s\n",
      "97:\tlearn: 0.0010464\ttotal: 16s\tremaining: 2m 27s\n",
      "98:\tlearn: 0.0010422\ttotal: 16.2s\tremaining: 2m 27s\n",
      "99:\tlearn: 0.0010296\ttotal: 16.3s\tremaining: 2m 26s\n",
      "100:\tlearn: 0.0010251\ttotal: 16.5s\tremaining: 2m 27s\n",
      "101:\tlearn: 0.0010216\ttotal: 16.7s\tremaining: 2m 26s\n",
      "102:\tlearn: 0.0010135\ttotal: 16.8s\tremaining: 2m 26s\n",
      "103:\tlearn: 0.0010130\ttotal: 17s\tremaining: 2m 26s\n",
      "104:\tlearn: 0.0009978\ttotal: 17.2s\tremaining: 2m 26s\n",
      "105:\tlearn: 0.0009628\ttotal: 17.3s\tremaining: 2m 26s\n",
      "106:\tlearn: 0.0009618\ttotal: 17.5s\tremaining: 2m 25s\n",
      "107:\tlearn: 0.0009356\ttotal: 17.7s\tremaining: 2m 25s\n",
      "108:\tlearn: 0.0009280\ttotal: 17.8s\tremaining: 2m 25s\n",
      "109:\tlearn: 0.0009235\ttotal: 18s\tremaining: 2m 25s\n",
      "110:\tlearn: 0.0009162\ttotal: 18.2s\tremaining: 2m 25s\n",
      "111:\tlearn: 0.0009112\ttotal: 18.3s\tremaining: 2m 25s\n",
      "112:\tlearn: 0.0009097\ttotal: 18.5s\tremaining: 2m 25s\n",
      "113:\tlearn: 0.0009074\ttotal: 18.6s\tremaining: 2m 24s\n",
      "114:\tlearn: 0.0008968\ttotal: 18.8s\tremaining: 2m 24s\n",
      "115:\tlearn: 0.0008919\ttotal: 19s\tremaining: 2m 24s\n",
      "116:\tlearn: 0.0008845\ttotal: 19.2s\tremaining: 2m 24s\n",
      "117:\tlearn: 0.0008739\ttotal: 19.3s\tremaining: 2m 24s\n",
      "118:\tlearn: 0.0008723\ttotal: 19.5s\tremaining: 2m 24s\n",
      "119:\tlearn: 0.0008653\ttotal: 19.6s\tremaining: 2m 24s\n",
      "120:\tlearn: 0.0008588\ttotal: 19.8s\tremaining: 2m 23s\n",
      "121:\tlearn: 0.0008408\ttotal: 20s\tremaining: 2m 24s\n",
      "122:\tlearn: 0.0008379\ttotal: 20.1s\tremaining: 2m 23s\n",
      "123:\tlearn: 0.0008359\ttotal: 20.3s\tremaining: 2m 23s\n",
      "124:\tlearn: 0.0008269\ttotal: 20.5s\tremaining: 2m 23s\n",
      "125:\tlearn: 0.0008043\ttotal: 20.6s\tremaining: 2m 23s\n",
      "126:\tlearn: 0.0008034\ttotal: 20.8s\tremaining: 2m 22s\n",
      "127:\tlearn: 0.0008020\ttotal: 20.9s\tremaining: 2m 22s\n",
      "128:\tlearn: 0.0008019\ttotal: 21.1s\tremaining: 2m 22s\n",
      "129:\tlearn: 0.0007921\ttotal: 21.2s\tremaining: 2m 22s\n",
      "130:\tlearn: 0.0007884\ttotal: 21.4s\tremaining: 2m 21s\n",
      "131:\tlearn: 0.0007866\ttotal: 21.5s\tremaining: 2m 21s\n",
      "132:\tlearn: 0.0007711\ttotal: 21.7s\tremaining: 2m 21s\n",
      "133:\tlearn: 0.0007571\ttotal: 21.8s\tremaining: 2m 21s\n",
      "134:\tlearn: 0.0007525\ttotal: 22s\tremaining: 2m 20s\n",
      "135:\tlearn: 0.0007515\ttotal: 22.1s\tremaining: 2m 20s\n",
      "136:\tlearn: 0.0007504\ttotal: 22.3s\tremaining: 2m 20s\n",
      "137:\tlearn: 0.0007496\ttotal: 22.4s\tremaining: 2m 20s\n",
      "138:\tlearn: 0.0007467\ttotal: 22.6s\tremaining: 2m 19s\n",
      "139:\tlearn: 0.0007450\ttotal: 22.7s\tremaining: 2m 19s\n",
      "140:\tlearn: 0.0007296\ttotal: 22.9s\tremaining: 2m 19s\n",
      "141:\tlearn: 0.0007265\ttotal: 23s\tremaining: 2m 19s\n",
      "142:\tlearn: 0.0007198\ttotal: 23.2s\tremaining: 2m 18s\n",
      "143:\tlearn: 0.0007192\ttotal: 23.3s\tremaining: 2m 18s\n",
      "144:\tlearn: 0.0007170\ttotal: 23.5s\tremaining: 2m 18s\n",
      "145:\tlearn: 0.0007159\ttotal: 23.6s\tremaining: 2m 18s\n",
      "146:\tlearn: 0.0007136\ttotal: 23.8s\tremaining: 2m 18s\n",
      "147:\tlearn: 0.0007130\ttotal: 23.9s\tremaining: 2m 17s\n",
      "148:\tlearn: 0.0007110\ttotal: 24.1s\tremaining: 2m 17s\n",
      "149:\tlearn: 0.0007087\ttotal: 24.2s\tremaining: 2m 17s\n",
      "150:\tlearn: 0.0007075\ttotal: 24.4s\tremaining: 2m 17s\n",
      "151:\tlearn: 0.0007024\ttotal: 24.5s\tremaining: 2m 16s\n",
      "152:\tlearn: 0.0007011\ttotal: 24.7s\tremaining: 2m 16s\n",
      "153:\tlearn: 0.0006991\ttotal: 24.8s\tremaining: 2m 16s\n",
      "154:\tlearn: 0.0006972\ttotal: 24.9s\tremaining: 2m 15s\n",
      "155:\tlearn: 0.0006964\ttotal: 25.1s\tremaining: 2m 15s\n",
      "156:\tlearn: 0.0006951\ttotal: 25.2s\tremaining: 2m 15s\n",
      "157:\tlearn: 0.0006931\ttotal: 25.4s\tremaining: 2m 15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 0.0006894\ttotal: 25.5s\tremaining: 2m 15s\n",
      "159:\tlearn: 0.0006823\ttotal: 25.7s\tremaining: 2m 14s\n",
      "160:\tlearn: 0.0006813\ttotal: 25.9s\tremaining: 2m 14s\n",
      "161:\tlearn: 0.0006807\ttotal: 26s\tremaining: 2m 14s\n",
      "162:\tlearn: 0.0006781\ttotal: 26.1s\tremaining: 2m 14s\n",
      "163:\tlearn: 0.0006759\ttotal: 26.3s\tremaining: 2m 13s\n",
      "164:\tlearn: 0.0006743\ttotal: 26.4s\tremaining: 2m 13s\n",
      "165:\tlearn: 0.0006740\ttotal: 26.6s\tremaining: 2m 13s\n",
      "166:\tlearn: 0.0006720\ttotal: 26.7s\tremaining: 2m 13s\n",
      "167:\tlearn: 0.0006713\ttotal: 26.9s\tremaining: 2m 13s\n",
      "168:\tlearn: 0.0006712\ttotal: 27s\tremaining: 2m 12s\n",
      "169:\tlearn: 0.0006603\ttotal: 27.2s\tremaining: 2m 12s\n",
      "170:\tlearn: 0.0006530\ttotal: 27.3s\tremaining: 2m 12s\n",
      "171:\tlearn: 0.0006516\ttotal: 27.5s\tremaining: 2m 12s\n",
      "172:\tlearn: 0.0006492\ttotal: 27.6s\tremaining: 2m 12s\n",
      "173:\tlearn: 0.0006483\ttotal: 27.8s\tremaining: 2m 11s\n",
      "174:\tlearn: 0.0006474\ttotal: 28s\tremaining: 2m 11s\n",
      "175:\tlearn: 0.0006464\ttotal: 28.1s\tremaining: 2m 11s\n",
      "176:\tlearn: 0.0006461\ttotal: 28.3s\tremaining: 2m 11s\n",
      "177:\tlearn: 0.0006461\ttotal: 28.4s\tremaining: 2m 11s\n",
      "178:\tlearn: 0.0006422\ttotal: 28.5s\tremaining: 2m 10s\n",
      "179:\tlearn: 0.0006395\ttotal: 28.7s\tremaining: 2m 10s\n",
      "180:\tlearn: 0.0006264\ttotal: 28.8s\tremaining: 2m 10s\n",
      "181:\tlearn: 0.0006262\ttotal: 29s\tremaining: 2m 10s\n",
      "182:\tlearn: 0.0006260\ttotal: 29.1s\tremaining: 2m 10s\n",
      "183:\tlearn: 0.0006258\ttotal: 29.3s\tremaining: 2m 9s\n",
      "184:\tlearn: 0.0006213\ttotal: 29.4s\tremaining: 2m 9s\n",
      "185:\tlearn: 0.0006213\ttotal: 29.6s\tremaining: 2m 9s\n",
      "186:\tlearn: 0.0006198\ttotal: 29.7s\tremaining: 2m 9s\n",
      "187:\tlearn: 0.0006195\ttotal: 29.9s\tremaining: 2m 9s\n",
      "188:\tlearn: 0.0006189\ttotal: 30s\tremaining: 2m 8s\n",
      "189:\tlearn: 0.0006176\ttotal: 30.2s\tremaining: 2m 8s\n",
      "190:\tlearn: 0.0006170\ttotal: 30.3s\tremaining: 2m 8s\n",
      "191:\tlearn: 0.0006148\ttotal: 30.5s\tremaining: 2m 8s\n",
      "192:\tlearn: 0.0006131\ttotal: 30.6s\tremaining: 2m 8s\n",
      "193:\tlearn: 0.0006122\ttotal: 30.8s\tremaining: 2m 7s\n",
      "194:\tlearn: 0.0006114\ttotal: 30.9s\tremaining: 2m 7s\n",
      "195:\tlearn: 0.0006056\ttotal: 31.1s\tremaining: 2m 7s\n",
      "196:\tlearn: 0.0006046\ttotal: 31.3s\tremaining: 2m 7s\n",
      "197:\tlearn: 0.0006033\ttotal: 31.4s\tremaining: 2m 7s\n",
      "198:\tlearn: 0.0006025\ttotal: 31.5s\tremaining: 2m 6s\n",
      "199:\tlearn: 0.0006018\ttotal: 31.7s\tremaining: 2m 6s\n",
      "200:\tlearn: 0.0005985\ttotal: 31.9s\tremaining: 2m 6s\n",
      "201:\tlearn: 0.0005947\ttotal: 32s\tremaining: 2m 6s\n",
      "202:\tlearn: 0.0005929\ttotal: 32.1s\tremaining: 2m 6s\n",
      "203:\tlearn: 0.0005894\ttotal: 32.3s\tremaining: 2m 6s\n",
      "204:\tlearn: 0.0005893\ttotal: 32.5s\tremaining: 2m 5s\n",
      "205:\tlearn: 0.0005838\ttotal: 32.6s\tremaining: 2m 5s\n",
      "206:\tlearn: 0.0005836\ttotal: 32.7s\tremaining: 2m 5s\n",
      "207:\tlearn: 0.0005829\ttotal: 32.9s\tremaining: 2m 5s\n",
      "208:\tlearn: 0.0005819\ttotal: 33.1s\tremaining: 2m 5s\n",
      "209:\tlearn: 0.0005815\ttotal: 33.2s\tremaining: 2m 4s\n",
      "210:\tlearn: 0.0005784\ttotal: 33.4s\tremaining: 2m 4s\n",
      "211:\tlearn: 0.0005783\ttotal: 33.5s\tremaining: 2m 4s\n",
      "212:\tlearn: 0.0005777\ttotal: 33.6s\tremaining: 2m 4s\n",
      "213:\tlearn: 0.0005770\ttotal: 33.8s\tremaining: 2m 4s\n",
      "214:\tlearn: 0.0005765\ttotal: 34s\tremaining: 2m 4s\n",
      "215:\tlearn: 0.0005753\ttotal: 34.1s\tremaining: 2m 3s\n",
      "216:\tlearn: 0.0005707\ttotal: 34.3s\tremaining: 2m 3s\n",
      "217:\tlearn: 0.0005703\ttotal: 34.4s\tremaining: 2m 3s\n",
      "218:\tlearn: 0.0005685\ttotal: 34.6s\tremaining: 2m 3s\n",
      "219:\tlearn: 0.0005671\ttotal: 34.7s\tremaining: 2m 3s\n",
      "220:\tlearn: 0.0005649\ttotal: 34.8s\tremaining: 2m 2s\n",
      "221:\tlearn: 0.0005628\ttotal: 35s\tremaining: 2m 2s\n",
      "222:\tlearn: 0.0005589\ttotal: 35.1s\tremaining: 2m 2s\n",
      "223:\tlearn: 0.0005545\ttotal: 35.3s\tremaining: 2m 2s\n",
      "224:\tlearn: 0.0005520\ttotal: 35.5s\tremaining: 2m 2s\n",
      "225:\tlearn: 0.0005503\ttotal: 35.6s\tremaining: 2m 1s\n",
      "226:\tlearn: 0.0005496\ttotal: 35.8s\tremaining: 2m 1s\n",
      "227:\tlearn: 0.0005484\ttotal: 35.9s\tremaining: 2m 1s\n",
      "228:\tlearn: 0.0005459\ttotal: 36s\tremaining: 2m 1s\n",
      "229:\tlearn: 0.0005444\ttotal: 36.2s\tremaining: 2m 1s\n",
      "230:\tlearn: 0.0005438\ttotal: 36.3s\tremaining: 2m\n",
      "231:\tlearn: 0.0005429\ttotal: 36.5s\tremaining: 2m\n",
      "232:\tlearn: 0.0005424\ttotal: 36.7s\tremaining: 2m\n",
      "233:\tlearn: 0.0005416\ttotal: 36.8s\tremaining: 2m\n",
      "234:\tlearn: 0.0005410\ttotal: 37s\tremaining: 2m\n",
      "235:\tlearn: 0.0005408\ttotal: 37.2s\tremaining: 2m\n",
      "236:\tlearn: 0.0005395\ttotal: 37.4s\tremaining: 2m\n",
      "237:\tlearn: 0.0005382\ttotal: 37.6s\tremaining: 2m\n",
      "238:\tlearn: 0.0005381\ttotal: 37.8s\tremaining: 2m\n",
      "239:\tlearn: 0.0005378\ttotal: 38s\tremaining: 2m\n",
      "240:\tlearn: 0.0005356\ttotal: 38.3s\tremaining: 2m\n",
      "241:\tlearn: 0.0005354\ttotal: 38.5s\tremaining: 2m\n",
      "242:\tlearn: 0.0005339\ttotal: 38.8s\tremaining: 2m\n",
      "243:\tlearn: 0.0005336\ttotal: 39s\tremaining: 2m\n",
      "244:\tlearn: 0.0005335\ttotal: 39.2s\tremaining: 2m\n",
      "245:\tlearn: 0.0005330\ttotal: 39.5s\tremaining: 2m\n",
      "246:\tlearn: 0.0005329\ttotal: 39.7s\tremaining: 2m 1s\n",
      "247:\tlearn: 0.0005312\ttotal: 40s\tremaining: 2m 1s\n",
      "248:\tlearn: 0.0005312\ttotal: 40.2s\tremaining: 2m 1s\n",
      "249:\tlearn: 0.0005307\ttotal: 40.4s\tremaining: 2m 1s\n",
      "250:\tlearn: 0.0005304\ttotal: 40.7s\tremaining: 2m 1s\n",
      "251:\tlearn: 0.0005303\ttotal: 40.9s\tremaining: 2m 1s\n",
      "252:\tlearn: 0.0005270\ttotal: 41.2s\tremaining: 2m 1s\n",
      "253:\tlearn: 0.0005254\ttotal: 41.4s\tremaining: 2m 1s\n",
      "254:\tlearn: 0.0005252\ttotal: 41.7s\tremaining: 2m 1s\n",
      "255:\tlearn: 0.0005243\ttotal: 41.9s\tremaining: 2m 1s\n",
      "256:\tlearn: 0.0005241\ttotal: 42.1s\tremaining: 2m 1s\n",
      "257:\tlearn: 0.0005235\ttotal: 42.4s\tremaining: 2m 1s\n",
      "258:\tlearn: 0.0005226\ttotal: 42.6s\tremaining: 2m 1s\n",
      "259:\tlearn: 0.0005198\ttotal: 42.9s\tremaining: 2m 1s\n",
      "260:\tlearn: 0.0005194\ttotal: 43.1s\tremaining: 2m 2s\n",
      "261:\tlearn: 0.0005188\ttotal: 43.3s\tremaining: 2m 2s\n",
      "262:\tlearn: 0.0005180\ttotal: 43.6s\tremaining: 2m 2s\n",
      "263:\tlearn: 0.0005167\ttotal: 43.8s\tremaining: 2m 2s\n",
      "264:\tlearn: 0.0005161\ttotal: 44.1s\tremaining: 2m 2s\n",
      "265:\tlearn: 0.0005162\ttotal: 44.3s\tremaining: 2m 2s\n",
      "266:\tlearn: 0.0005156\ttotal: 44.5s\tremaining: 2m 2s\n",
      "267:\tlearn: 0.0005153\ttotal: 44.8s\tremaining: 2m 2s\n",
      "268:\tlearn: 0.0005152\ttotal: 45s\tremaining: 2m 2s\n",
      "269:\tlearn: 0.0005146\ttotal: 45.2s\tremaining: 2m 2s\n",
      "270:\tlearn: 0.0005146\ttotal: 45.5s\tremaining: 2m 2s\n",
      "271:\tlearn: 0.0005144\ttotal: 45.7s\tremaining: 2m 2s\n",
      "272:\tlearn: 0.0005141\ttotal: 46s\tremaining: 2m 2s\n",
      "273:\tlearn: 0.0005130\ttotal: 46.2s\tremaining: 2m 2s\n",
      "274:\tlearn: 0.0005124\ttotal: 46.4s\tremaining: 2m 2s\n",
      "275:\tlearn: 0.0005121\ttotal: 46.7s\tremaining: 2m 2s\n",
      "276:\tlearn: 0.0005115\ttotal: 46.9s\tremaining: 2m 2s\n",
      "277:\tlearn: 0.0005108\ttotal: 47.2s\tremaining: 2m 2s\n",
      "278:\tlearn: 0.0005104\ttotal: 47.4s\tremaining: 2m 2s\n",
      "279:\tlearn: 0.0005101\ttotal: 47.6s\tremaining: 2m 2s\n",
      "280:\tlearn: 0.0005097\ttotal: 47.7s\tremaining: 2m 2s\n",
      "281:\tlearn: 0.0005091\ttotal: 47.9s\tremaining: 2m 1s\n",
      "282:\tlearn: 0.0005090\ttotal: 48.1s\tremaining: 2m 1s\n",
      "283:\tlearn: 0.0005081\ttotal: 48.3s\tremaining: 2m 1s\n",
      "284:\tlearn: 0.0005080\ttotal: 48.4s\tremaining: 2m 1s\n",
      "285:\tlearn: 0.0005067\ttotal: 48.6s\tremaining: 2m 1s\n",
      "286:\tlearn: 0.0005067\ttotal: 48.8s\tremaining: 2m 1s\n",
      "287:\tlearn: 0.0005067\ttotal: 48.9s\tremaining: 2m\n",
      "288:\tlearn: 0.0005067\ttotal: 49.1s\tremaining: 2m\n",
      "289:\tlearn: 0.0005061\ttotal: 49.2s\tremaining: 2m\n",
      "290:\tlearn: 0.0005055\ttotal: 49.4s\tremaining: 2m\n",
      "291:\tlearn: 0.0005055\ttotal: 49.6s\tremaining: 2m\n",
      "292:\tlearn: 0.0005049\ttotal: 49.7s\tremaining: 1m 59s\n",
      "293:\tlearn: 0.0005049\ttotal: 49.9s\tremaining: 1m 59s\n",
      "294:\tlearn: 0.0005042\ttotal: 50s\tremaining: 1m 59s\n",
      "295:\tlearn: 0.0005039\ttotal: 50.2s\tremaining: 1m 59s\n",
      "296:\tlearn: 0.0005033\ttotal: 50.3s\tremaining: 1m 59s\n",
      "297:\tlearn: 0.0005031\ttotal: 50.5s\tremaining: 1m 58s\n",
      "298:\tlearn: 0.0005031\ttotal: 50.7s\tremaining: 1m 58s\n",
      "299:\tlearn: 0.0005030\ttotal: 50.8s\tremaining: 1m 58s\n",
      "300:\tlearn: 0.0005030\ttotal: 50.9s\tremaining: 1m 58s\n",
      "301:\tlearn: 0.0005021\ttotal: 51.1s\tremaining: 1m 58s\n",
      "302:\tlearn: 0.0005021\ttotal: 51.2s\tremaining: 1m 57s\n",
      "303:\tlearn: 0.0005019\ttotal: 51.4s\tremaining: 1m 57s\n",
      "304:\tlearn: 0.0005019\ttotal: 51.5s\tremaining: 1m 57s\n",
      "305:\tlearn: 0.0005018\ttotal: 51.7s\tremaining: 1m 57s\n",
      "306:\tlearn: 0.0005018\ttotal: 51.8s\tremaining: 1m 56s\n",
      "307:\tlearn: 0.0005010\ttotal: 52s\tremaining: 1m 56s\n",
      "308:\tlearn: 0.0005005\ttotal: 52.1s\tremaining: 1m 56s\n",
      "309:\tlearn: 0.0004994\ttotal: 52.3s\tremaining: 1m 56s\n",
      "310:\tlearn: 0.0004992\ttotal: 52.4s\tremaining: 1m 56s\n",
      "311:\tlearn: 0.0004991\ttotal: 52.6s\tremaining: 1m 55s\n",
      "312:\tlearn: 0.0004986\ttotal: 52.7s\tremaining: 1m 55s\n",
      "313:\tlearn: 0.0004981\ttotal: 52.9s\tremaining: 1m 55s\n",
      "314:\tlearn: 0.0004977\ttotal: 53s\tremaining: 1m 55s\n",
      "315:\tlearn: 0.0004961\ttotal: 53.2s\tremaining: 1m 55s\n",
      "316:\tlearn: 0.0004955\ttotal: 53.3s\tremaining: 1m 54s\n",
      "317:\tlearn: 0.0004951\ttotal: 53.5s\tremaining: 1m 54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318:\tlearn: 0.0004950\ttotal: 53.6s\tremaining: 1m 54s\n",
      "319:\tlearn: 0.0004950\ttotal: 53.7s\tremaining: 1m 54s\n",
      "320:\tlearn: 0.0004946\ttotal: 53.9s\tremaining: 1m 54s\n",
      "321:\tlearn: 0.0004943\ttotal: 54s\tremaining: 1m 53s\n",
      "322:\tlearn: 0.0004943\ttotal: 54.2s\tremaining: 1m 53s\n",
      "323:\tlearn: 0.0004939\ttotal: 54.3s\tremaining: 1m 53s\n",
      "324:\tlearn: 0.0004937\ttotal: 54.5s\tremaining: 1m 53s\n",
      "325:\tlearn: 0.0004936\ttotal: 54.6s\tremaining: 1m 52s\n",
      "326:\tlearn: 0.0004934\ttotal: 54.8s\tremaining: 1m 52s\n",
      "327:\tlearn: 0.0004934\ttotal: 54.9s\tremaining: 1m 52s\n",
      "328:\tlearn: 0.0004934\ttotal: 55.1s\tremaining: 1m 52s\n",
      "329:\tlearn: 0.0004930\ttotal: 55.2s\tremaining: 1m 52s\n",
      "330:\tlearn: 0.0004928\ttotal: 55.4s\tremaining: 1m 51s\n",
      "331:\tlearn: 0.0004924\ttotal: 55.5s\tremaining: 1m 51s\n",
      "332:\tlearn: 0.0004917\ttotal: 55.6s\tremaining: 1m 51s\n",
      "333:\tlearn: 0.0004916\ttotal: 55.8s\tremaining: 1m 51s\n",
      "334:\tlearn: 0.0004913\ttotal: 55.9s\tremaining: 1m 51s\n",
      "335:\tlearn: 0.0004912\ttotal: 56.1s\tremaining: 1m 50s\n",
      "336:\tlearn: 0.0004912\ttotal: 56.2s\tremaining: 1m 50s\n",
      "337:\tlearn: 0.0004912\ttotal: 56.4s\tremaining: 1m 50s\n",
      "338:\tlearn: 0.0004911\ttotal: 56.5s\tremaining: 1m 50s\n",
      "339:\tlearn: 0.0004908\ttotal: 56.7s\tremaining: 1m 50s\n",
      "340:\tlearn: 0.0004906\ttotal: 56.8s\tremaining: 1m 49s\n",
      "341:\tlearn: 0.0004904\ttotal: 57s\tremaining: 1m 49s\n",
      "342:\tlearn: 0.0004890\ttotal: 57.1s\tremaining: 1m 49s\n",
      "343:\tlearn: 0.0004885\ttotal: 57.2s\tremaining: 1m 49s\n",
      "344:\tlearn: 0.0004884\ttotal: 57.4s\tremaining: 1m 48s\n",
      "345:\tlearn: 0.0004880\ttotal: 57.6s\tremaining: 1m 48s\n",
      "346:\tlearn: 0.0004879\ttotal: 57.7s\tremaining: 1m 48s\n",
      "347:\tlearn: 0.0004879\ttotal: 57.9s\tremaining: 1m 48s\n",
      "348:\tlearn: 0.0004879\ttotal: 58s\tremaining: 1m 48s\n",
      "349:\tlearn: 0.0004878\ttotal: 58.2s\tremaining: 1m 48s\n",
      "350:\tlearn: 0.0004876\ttotal: 58.4s\tremaining: 1m 47s\n",
      "351:\tlearn: 0.0004874\ttotal: 58.5s\tremaining: 1m 47s\n",
      "352:\tlearn: 0.0004872\ttotal: 58.7s\tremaining: 1m 47s\n",
      "353:\tlearn: 0.0004871\ttotal: 58.8s\tremaining: 1m 47s\n",
      "354:\tlearn: 0.0004866\ttotal: 59s\tremaining: 1m 47s\n",
      "355:\tlearn: 0.0004852\ttotal: 59.1s\tremaining: 1m 46s\n",
      "356:\tlearn: 0.0004852\ttotal: 59.3s\tremaining: 1m 46s\n",
      "357:\tlearn: 0.0004852\ttotal: 59.5s\tremaining: 1m 46s\n",
      "358:\tlearn: 0.0004845\ttotal: 59.6s\tremaining: 1m 46s\n",
      "359:\tlearn: 0.0004840\ttotal: 59.8s\tremaining: 1m 46s\n",
      "360:\tlearn: 0.0004841\ttotal: 59.9s\tremaining: 1m 46s\n",
      "361:\tlearn: 0.0004840\ttotal: 1m\tremaining: 1m 45s\n",
      "362:\tlearn: 0.0004837\ttotal: 1m\tremaining: 1m 45s\n",
      "363:\tlearn: 0.0004808\ttotal: 1m\tremaining: 1m 45s\n",
      "364:\tlearn: 0.0004803\ttotal: 1m\tremaining: 1m 45s\n",
      "365:\tlearn: 0.0004801\ttotal: 1m\tremaining: 1m 45s\n",
      "366:\tlearn: 0.0004800\ttotal: 1m\tremaining: 1m 45s\n",
      "367:\tlearn: 0.0004800\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "368:\tlearn: 0.0004761\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "369:\tlearn: 0.0004758\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "370:\tlearn: 0.0004756\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "371:\tlearn: 0.0004755\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "372:\tlearn: 0.0004752\ttotal: 1m 1s\tremaining: 1m 43s\n",
      "373:\tlearn: 0.0004753\ttotal: 1m 1s\tremaining: 1m 43s\n",
      "374:\tlearn: 0.0004752\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "375:\tlearn: 0.0004752\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "376:\tlearn: 0.0004751\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "377:\tlearn: 0.0004750\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "378:\tlearn: 0.0004746\ttotal: 1m 3s\tremaining: 1m 43s\n",
      "379:\tlearn: 0.0004744\ttotal: 1m 3s\tremaining: 1m 43s\n",
      "380:\tlearn: 0.0004743\ttotal: 1m 3s\tremaining: 1m 43s\n",
      "381:\tlearn: 0.0004740\ttotal: 1m 3s\tremaining: 1m 43s\n",
      "382:\tlearn: 0.0004740\ttotal: 1m 4s\tremaining: 1m 43s\n",
      "383:\tlearn: 0.0004738\ttotal: 1m 4s\tremaining: 1m 43s\n",
      "384:\tlearn: 0.0004737\ttotal: 1m 4s\tremaining: 1m 42s\n",
      "385:\tlearn: 0.0004736\ttotal: 1m 4s\tremaining: 1m 42s\n",
      "386:\tlearn: 0.0004736\ttotal: 1m 4s\tremaining: 1m 42s\n",
      "387:\tlearn: 0.0004735\ttotal: 1m 5s\tremaining: 1m 42s\n",
      "388:\tlearn: 0.0004734\ttotal: 1m 5s\tremaining: 1m 42s\n",
      "389:\tlearn: 0.0004731\ttotal: 1m 5s\tremaining: 1m 42s\n",
      "390:\tlearn: 0.0004731\ttotal: 1m 5s\tremaining: 1m 42s\n",
      "391:\tlearn: 0.0004732\ttotal: 1m 6s\tremaining: 1m 42s\n",
      "392:\tlearn: 0.0004728\ttotal: 1m 6s\tremaining: 1m 42s\n",
      "393:\tlearn: 0.0004727\ttotal: 1m 6s\tremaining: 1m 42s\n",
      "394:\tlearn: 0.0004726\ttotal: 1m 6s\tremaining: 1m 42s\n",
      "395:\tlearn: 0.0004725\ttotal: 1m 7s\tremaining: 1m 42s\n",
      "396:\tlearn: 0.0004725\ttotal: 1m 7s\tremaining: 1m 42s\n",
      "397:\tlearn: 0.0004720\ttotal: 1m 7s\tremaining: 1m 42s\n",
      "398:\tlearn: 0.0004719\ttotal: 1m 7s\tremaining: 1m 42s\n",
      "399:\tlearn: 0.0004718\ttotal: 1m 8s\tremaining: 1m 42s\n",
      "400:\tlearn: 0.0004717\ttotal: 1m 8s\tremaining: 1m 41s\n",
      "401:\tlearn: 0.0004714\ttotal: 1m 8s\tremaining: 1m 41s\n",
      "402:\tlearn: 0.0004702\ttotal: 1m 8s\tremaining: 1m 41s\n",
      "403:\tlearn: 0.0004698\ttotal: 1m 8s\tremaining: 1m 41s\n",
      "404:\tlearn: 0.0004694\ttotal: 1m 9s\tremaining: 1m 41s\n",
      "405:\tlearn: 0.0004692\ttotal: 1m 9s\tremaining: 1m 41s\n",
      "406:\tlearn: 0.0004688\ttotal: 1m 9s\tremaining: 1m 41s\n",
      "407:\tlearn: 0.0004688\ttotal: 1m 9s\tremaining: 1m 41s\n",
      "408:\tlearn: 0.0004688\ttotal: 1m 10s\tremaining: 1m 41s\n",
      "409:\tlearn: 0.0004681\ttotal: 1m 10s\tremaining: 1m 41s\n",
      "410:\tlearn: 0.0004680\ttotal: 1m 10s\tremaining: 1m 41s\n",
      "411:\tlearn: 0.0004678\ttotal: 1m 10s\tremaining: 1m 41s\n",
      "412:\tlearn: 0.0004667\ttotal: 1m 11s\tremaining: 1m 41s\n",
      "413:\tlearn: 0.0004651\ttotal: 1m 11s\tremaining: 1m 41s\n",
      "414:\tlearn: 0.0004650\ttotal: 1m 11s\tremaining: 1m 41s\n",
      "415:\tlearn: 0.0004644\ttotal: 1m 11s\tremaining: 1m 40s\n",
      "416:\tlearn: 0.0004643\ttotal: 1m 12s\tremaining: 1m 40s\n",
      "417:\tlearn: 0.0004643\ttotal: 1m 12s\tremaining: 1m 40s\n",
      "418:\tlearn: 0.0004643\ttotal: 1m 12s\tremaining: 1m 40s\n",
      "419:\tlearn: 0.0004642\ttotal: 1m 12s\tremaining: 1m 40s\n",
      "420:\tlearn: 0.0004642\ttotal: 1m 13s\tremaining: 1m 40s\n",
      "421:\tlearn: 0.0004642\ttotal: 1m 13s\tremaining: 1m 40s\n",
      "422:\tlearn: 0.0004641\ttotal: 1m 13s\tremaining: 1m 40s\n",
      "423:\tlearn: 0.0004639\ttotal: 1m 13s\tremaining: 1m 40s\n",
      "424:\tlearn: 0.0004637\ttotal: 1m 14s\tremaining: 1m 40s\n",
      "425:\tlearn: 0.0004636\ttotal: 1m 14s\tremaining: 1m 40s\n",
      "426:\tlearn: 0.0004634\ttotal: 1m 14s\tremaining: 1m 39s\n",
      "427:\tlearn: 0.0004633\ttotal: 1m 14s\tremaining: 1m 39s\n",
      "428:\tlearn: 0.0004633\ttotal: 1m 14s\tremaining: 1m 39s\n",
      "429:\tlearn: 0.0004628\ttotal: 1m 15s\tremaining: 1m 39s\n",
      "430:\tlearn: 0.0004628\ttotal: 1m 15s\tremaining: 1m 39s\n",
      "431:\tlearn: 0.0004626\ttotal: 1m 15s\tremaining: 1m 39s\n",
      "432:\tlearn: 0.0004625\ttotal: 1m 15s\tremaining: 1m 39s\n",
      "433:\tlearn: 0.0004623\ttotal: 1m 16s\tremaining: 1m 39s\n",
      "434:\tlearn: 0.0004623\ttotal: 1m 16s\tremaining: 1m 39s\n",
      "435:\tlearn: 0.0004622\ttotal: 1m 16s\tremaining: 1m 39s\n",
      "436:\tlearn: 0.0004620\ttotal: 1m 16s\tremaining: 1m 39s\n",
      "437:\tlearn: 0.0004607\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "438:\tlearn: 0.0004598\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "439:\tlearn: 0.0004598\ttotal: 1m 17s\tremaining: 1m 38s\n",
      "440:\tlearn: 0.0004597\ttotal: 1m 17s\tremaining: 1m 38s\n",
      "441:\tlearn: 0.0004592\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "442:\tlearn: 0.0004592\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "443:\tlearn: 0.0004590\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "444:\tlearn: 0.0004588\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "445:\tlearn: 0.0004588\ttotal: 1m 19s\tremaining: 1m 38s\n",
      "446:\tlearn: 0.0004584\ttotal: 1m 19s\tremaining: 1m 38s\n",
      "447:\tlearn: 0.0004584\ttotal: 1m 19s\tremaining: 1m 38s\n",
      "448:\tlearn: 0.0004569\ttotal: 1m 19s\tremaining: 1m 38s\n",
      "449:\tlearn: 0.0004567\ttotal: 1m 20s\tremaining: 1m 38s\n",
      "450:\tlearn: 0.0004567\ttotal: 1m 20s\tremaining: 1m 37s\n",
      "451:\tlearn: 0.0004564\ttotal: 1m 20s\tremaining: 1m 37s\n",
      "452:\tlearn: 0.0004563\ttotal: 1m 20s\tremaining: 1m 37s\n",
      "453:\tlearn: 0.0004562\ttotal: 1m 21s\tremaining: 1m 37s\n",
      "454:\tlearn: 0.0004561\ttotal: 1m 21s\tremaining: 1m 37s\n",
      "455:\tlearn: 0.0004561\ttotal: 1m 21s\tremaining: 1m 37s\n",
      "456:\tlearn: 0.0004558\ttotal: 1m 21s\tremaining: 1m 37s\n",
      "457:\tlearn: 0.0004557\ttotal: 1m 22s\tremaining: 1m 37s\n",
      "458:\tlearn: 0.0004557\ttotal: 1m 22s\tremaining: 1m 37s\n",
      "459:\tlearn: 0.0004537\ttotal: 1m 22s\tremaining: 1m 36s\n",
      "460:\tlearn: 0.0004535\ttotal: 1m 22s\tremaining: 1m 36s\n",
      "461:\tlearn: 0.0004532\ttotal: 1m 23s\tremaining: 1m 36s\n",
      "462:\tlearn: 0.0004531\ttotal: 1m 23s\tremaining: 1m 36s\n",
      "463:\tlearn: 0.0004531\ttotal: 1m 23s\tremaining: 1m 36s\n",
      "464:\tlearn: 0.0004531\ttotal: 1m 23s\tremaining: 1m 36s\n",
      "465:\tlearn: 0.0004531\ttotal: 1m 23s\tremaining: 1m 35s\n",
      "466:\tlearn: 0.0004530\ttotal: 1m 23s\tremaining: 1m 35s\n",
      "467:\tlearn: 0.0004508\ttotal: 1m 24s\tremaining: 1m 35s\n",
      "468:\tlearn: 0.0004508\ttotal: 1m 24s\tremaining: 1m 35s\n",
      "469:\tlearn: 0.0004503\ttotal: 1m 24s\tremaining: 1m 35s\n",
      "470:\tlearn: 0.0004503\ttotal: 1m 24s\tremaining: 1m 34s\n",
      "471:\tlearn: 0.0004499\ttotal: 1m 24s\tremaining: 1m 34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472:\tlearn: 0.0004480\ttotal: 1m 24s\tremaining: 1m 34s\n",
      "473:\tlearn: 0.0004480\ttotal: 1m 24s\tremaining: 1m 34s\n",
      "474:\tlearn: 0.0004470\ttotal: 1m 25s\tremaining: 1m 34s\n",
      "475:\tlearn: 0.0004469\ttotal: 1m 25s\tremaining: 1m 33s\n",
      "476:\tlearn: 0.0004468\ttotal: 1m 25s\tremaining: 1m 33s\n",
      "477:\tlearn: 0.0004462\ttotal: 1m 25s\tremaining: 1m 33s\n",
      "478:\tlearn: 0.0004462\ttotal: 1m 25s\tremaining: 1m 33s\n",
      "479:\tlearn: 0.0004462\ttotal: 1m 25s\tremaining: 1m 32s\n",
      "480:\tlearn: 0.0004460\ttotal: 1m 25s\tremaining: 1m 32s\n",
      "481:\tlearn: 0.0004457\ttotal: 1m 26s\tremaining: 1m 32s\n",
      "482:\tlearn: 0.0004455\ttotal: 1m 26s\tremaining: 1m 32s\n",
      "483:\tlearn: 0.0004455\ttotal: 1m 26s\tremaining: 1m 32s\n",
      "484:\tlearn: 0.0004454\ttotal: 1m 26s\tremaining: 1m 31s\n",
      "485:\tlearn: 0.0004455\ttotal: 1m 26s\tremaining: 1m 31s\n",
      "486:\tlearn: 0.0004449\ttotal: 1m 26s\tremaining: 1m 31s\n",
      "487:\tlearn: 0.0004447\ttotal: 1m 26s\tremaining: 1m 31s\n",
      "488:\tlearn: 0.0004446\ttotal: 1m 27s\tremaining: 1m 31s\n",
      "489:\tlearn: 0.0004443\ttotal: 1m 27s\tremaining: 1m 30s\n",
      "490:\tlearn: 0.0004443\ttotal: 1m 27s\tremaining: 1m 30s\n",
      "491:\tlearn: 0.0004438\ttotal: 1m 27s\tremaining: 1m 30s\n",
      "492:\tlearn: 0.0004427\ttotal: 1m 27s\tremaining: 1m 30s\n",
      "493:\tlearn: 0.0004426\ttotal: 1m 27s\tremaining: 1m 30s\n",
      "494:\tlearn: 0.0004415\ttotal: 1m 28s\tremaining: 1m 29s\n",
      "495:\tlearn: 0.0004413\ttotal: 1m 28s\tremaining: 1m 29s\n",
      "496:\tlearn: 0.0004413\ttotal: 1m 28s\tremaining: 1m 29s\n",
      "497:\tlearn: 0.0004412\ttotal: 1m 28s\tremaining: 1m 29s\n",
      "498:\tlearn: 0.0004412\ttotal: 1m 28s\tremaining: 1m 29s\n",
      "499:\tlearn: 0.0004411\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "500:\tlearn: 0.0004410\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "501:\tlearn: 0.0004409\ttotal: 1m 29s\tremaining: 1m 28s\n",
      "502:\tlearn: 0.0004408\ttotal: 1m 29s\tremaining: 1m 28s\n",
      "503:\tlearn: 0.0004407\ttotal: 1m 29s\tremaining: 1m 28s\n",
      "504:\tlearn: 0.0004408\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "505:\tlearn: 0.0004408\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "506:\tlearn: 0.0004405\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "507:\tlearn: 0.0004405\ttotal: 1m 30s\tremaining: 1m 27s\n",
      "508:\tlearn: 0.0004405\ttotal: 1m 30s\tremaining: 1m 27s\n",
      "509:\tlearn: 0.0004405\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "510:\tlearn: 0.0004387\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "511:\tlearn: 0.0004386\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "512:\tlearn: 0.0004384\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "513:\tlearn: 0.0004378\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "514:\tlearn: 0.0004377\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "515:\tlearn: 0.0004376\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "516:\tlearn: 0.0004376\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "517:\tlearn: 0.0004376\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "518:\tlearn: 0.0004375\ttotal: 1m 31s\tremaining: 1m 24s\n",
      "519:\tlearn: 0.0004375\ttotal: 1m 31s\tremaining: 1m 24s\n",
      "520:\tlearn: 0.0004375\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "521:\tlearn: 0.0004374\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "522:\tlearn: 0.0004373\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "523:\tlearn: 0.0004364\ttotal: 1m 32s\tremaining: 1m 23s\n",
      "524:\tlearn: 0.0004364\ttotal: 1m 32s\tremaining: 1m 23s\n",
      "525:\tlearn: 0.0004364\ttotal: 1m 32s\tremaining: 1m 23s\n",
      "526:\tlearn: 0.0004364\ttotal: 1m 32s\tremaining: 1m 23s\n",
      "527:\tlearn: 0.0004363\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "528:\tlearn: 0.0004363\ttotal: 1m 33s\tremaining: 1m 22s\n",
      "529:\tlearn: 0.0004363\ttotal: 1m 33s\tremaining: 1m 22s\n",
      "530:\tlearn: 0.0004362\ttotal: 1m 33s\tremaining: 1m 22s\n",
      "531:\tlearn: 0.0004359\ttotal: 1m 33s\tremaining: 1m 22s\n",
      "532:\tlearn: 0.0004359\ttotal: 1m 33s\tremaining: 1m 22s\n",
      "533:\tlearn: 0.0004359\ttotal: 1m 33s\tremaining: 1m 21s\n",
      "534:\tlearn: 0.0004358\ttotal: 1m 34s\tremaining: 1m 21s\n",
      "535:\tlearn: 0.0004358\ttotal: 1m 34s\tremaining: 1m 21s\n",
      "536:\tlearn: 0.0004358\ttotal: 1m 34s\tremaining: 1m 21s\n",
      "537:\tlearn: 0.0004358\ttotal: 1m 34s\tremaining: 1m 21s\n",
      "538:\tlearn: 0.0004354\ttotal: 1m 34s\tremaining: 1m 20s\n",
      "539:\tlearn: 0.0004353\ttotal: 1m 34s\tremaining: 1m 20s\n",
      "540:\tlearn: 0.0004353\ttotal: 1m 34s\tremaining: 1m 20s\n",
      "541:\tlearn: 0.0004353\ttotal: 1m 35s\tremaining: 1m 20s\n",
      "542:\tlearn: 0.0004353\ttotal: 1m 35s\tremaining: 1m 20s\n",
      "543:\tlearn: 0.0004352\ttotal: 1m 35s\tremaining: 1m 19s\n",
      "544:\tlearn: 0.0004352\ttotal: 1m 35s\tremaining: 1m 19s\n",
      "545:\tlearn: 0.0004352\ttotal: 1m 35s\tremaining: 1m 19s\n",
      "546:\tlearn: 0.0004351\ttotal: 1m 35s\tremaining: 1m 19s\n",
      "547:\tlearn: 0.0004351\ttotal: 1m 35s\tremaining: 1m 19s\n",
      "548:\tlearn: 0.0004351\ttotal: 1m 36s\tremaining: 1m 18s\n",
      "549:\tlearn: 0.0004350\ttotal: 1m 36s\tremaining: 1m 18s\n",
      "550:\tlearn: 0.0004348\ttotal: 1m 36s\tremaining: 1m 18s\n",
      "551:\tlearn: 0.0004349\ttotal: 1m 36s\tremaining: 1m 18s\n",
      "552:\tlearn: 0.0004349\ttotal: 1m 36s\tremaining: 1m 18s\n",
      "553:\tlearn: 0.0004348\ttotal: 1m 36s\tremaining: 1m 17s\n",
      "554:\tlearn: 0.0004348\ttotal: 1m 37s\tremaining: 1m 17s\n",
      "555:\tlearn: 0.0004348\ttotal: 1m 37s\tremaining: 1m 17s\n",
      "556:\tlearn: 0.0004348\ttotal: 1m 37s\tremaining: 1m 17s\n",
      "557:\tlearn: 0.0004348\ttotal: 1m 37s\tremaining: 1m 17s\n",
      "558:\tlearn: 0.0004348\ttotal: 1m 37s\tremaining: 1m 17s\n",
      "559:\tlearn: 0.0004346\ttotal: 1m 37s\tremaining: 1m 16s\n",
      "560:\tlearn: 0.0004345\ttotal: 1m 37s\tremaining: 1m 16s\n",
      "561:\tlearn: 0.0004345\ttotal: 1m 38s\tremaining: 1m 16s\n",
      "562:\tlearn: 0.0004341\ttotal: 1m 38s\tremaining: 1m 16s\n",
      "563:\tlearn: 0.0004341\ttotal: 1m 38s\tremaining: 1m 16s\n",
      "564:\tlearn: 0.0004340\ttotal: 1m 38s\tremaining: 1m 15s\n",
      "565:\tlearn: 0.0004340\ttotal: 1m 38s\tremaining: 1m 15s\n",
      "566:\tlearn: 0.0004340\ttotal: 1m 38s\tremaining: 1m 15s\n",
      "567:\tlearn: 0.0004340\ttotal: 1m 38s\tremaining: 1m 15s\n",
      "568:\tlearn: 0.0004340\ttotal: 1m 39s\tremaining: 1m 15s\n",
      "569:\tlearn: 0.0004339\ttotal: 1m 39s\tremaining: 1m 14s\n",
      "570:\tlearn: 0.0004338\ttotal: 1m 39s\tremaining: 1m 14s\n",
      "571:\tlearn: 0.0004338\ttotal: 1m 39s\tremaining: 1m 14s\n",
      "572:\tlearn: 0.0004337\ttotal: 1m 39s\tremaining: 1m 14s\n",
      "573:\tlearn: 0.0004315\ttotal: 1m 39s\tremaining: 1m 14s\n",
      "574:\tlearn: 0.0004300\ttotal: 1m 40s\tremaining: 1m 13s\n",
      "575:\tlearn: 0.0004299\ttotal: 1m 40s\tremaining: 1m 13s\n",
      "576:\tlearn: 0.0004299\ttotal: 1m 40s\tremaining: 1m 13s\n",
      "577:\tlearn: 0.0004298\ttotal: 1m 40s\tremaining: 1m 13s\n",
      "578:\tlearn: 0.0004298\ttotal: 1m 40s\tremaining: 1m 13s\n",
      "579:\tlearn: 0.0004286\ttotal: 1m 40s\tremaining: 1m 12s\n",
      "580:\tlearn: 0.0004284\ttotal: 1m 40s\tremaining: 1m 12s\n",
      "581:\tlearn: 0.0004276\ttotal: 1m 41s\tremaining: 1m 12s\n",
      "582:\tlearn: 0.0004275\ttotal: 1m 41s\tremaining: 1m 12s\n",
      "583:\tlearn: 0.0004274\ttotal: 1m 41s\tremaining: 1m 12s\n",
      "584:\tlearn: 0.0004275\ttotal: 1m 41s\tremaining: 1m 12s\n",
      "585:\tlearn: 0.0004274\ttotal: 1m 41s\tremaining: 1m 11s\n",
      "586:\tlearn: 0.0004274\ttotal: 1m 41s\tremaining: 1m 11s\n",
      "587:\tlearn: 0.0004274\ttotal: 1m 41s\tremaining: 1m 11s\n",
      "588:\tlearn: 0.0004273\ttotal: 1m 42s\tremaining: 1m 11s\n",
      "589:\tlearn: 0.0004273\ttotal: 1m 42s\tremaining: 1m 11s\n",
      "590:\tlearn: 0.0004273\ttotal: 1m 42s\tremaining: 1m 10s\n",
      "591:\tlearn: 0.0004270\ttotal: 1m 42s\tremaining: 1m 10s\n",
      "592:\tlearn: 0.0004268\ttotal: 1m 42s\tremaining: 1m 10s\n",
      "593:\tlearn: 0.0004268\ttotal: 1m 42s\tremaining: 1m 10s\n",
      "594:\tlearn: 0.0004269\ttotal: 1m 42s\tremaining: 1m 10s\n",
      "595:\tlearn: 0.0004269\ttotal: 1m 43s\tremaining: 1m 9s\n",
      "596:\tlearn: 0.0004268\ttotal: 1m 43s\tremaining: 1m 9s\n",
      "597:\tlearn: 0.0004268\ttotal: 1m 43s\tremaining: 1m 9s\n",
      "598:\tlearn: 0.0004266\ttotal: 1m 43s\tremaining: 1m 9s\n",
      "599:\tlearn: 0.0004265\ttotal: 1m 43s\tremaining: 1m 9s\n",
      "600:\tlearn: 0.0004263\ttotal: 1m 43s\tremaining: 1m 8s\n",
      "601:\tlearn: 0.0004264\ttotal: 1m 44s\tremaining: 1m 8s\n",
      "602:\tlearn: 0.0004263\ttotal: 1m 44s\tremaining: 1m 8s\n",
      "603:\tlearn: 0.0004263\ttotal: 1m 44s\tremaining: 1m 8s\n",
      "604:\tlearn: 0.0004263\ttotal: 1m 44s\tremaining: 1m 8s\n",
      "605:\tlearn: 0.0004262\ttotal: 1m 44s\tremaining: 1m 8s\n",
      "606:\tlearn: 0.0004262\ttotal: 1m 44s\tremaining: 1m 7s\n",
      "607:\tlearn: 0.0004261\ttotal: 1m 44s\tremaining: 1m 7s\n",
      "608:\tlearn: 0.0004261\ttotal: 1m 45s\tremaining: 1m 7s\n",
      "609:\tlearn: 0.0004260\ttotal: 1m 45s\tremaining: 1m 7s\n",
      "610:\tlearn: 0.0004258\ttotal: 1m 45s\tremaining: 1m 7s\n",
      "611:\tlearn: 0.0004259\ttotal: 1m 45s\tremaining: 1m 6s\n",
      "612:\tlearn: 0.0004257\ttotal: 1m 45s\tremaining: 1m 6s\n",
      "613:\tlearn: 0.0004257\ttotal: 1m 45s\tremaining: 1m 6s\n",
      "614:\tlearn: 0.0004258\ttotal: 1m 46s\tremaining: 1m 6s\n",
      "615:\tlearn: 0.0004256\ttotal: 1m 46s\tremaining: 1m 6s\n",
      "616:\tlearn: 0.0004257\ttotal: 1m 46s\tremaining: 1m 6s\n",
      "617:\tlearn: 0.0004256\ttotal: 1m 46s\tremaining: 1m 5s\n",
      "618:\tlearn: 0.0004256\ttotal: 1m 46s\tremaining: 1m 5s\n",
      "619:\tlearn: 0.0004256\ttotal: 1m 46s\tremaining: 1m 5s\n",
      "620:\tlearn: 0.0004256\ttotal: 1m 46s\tremaining: 1m 5s\n",
      "621:\tlearn: 0.0004255\ttotal: 1m 47s\tremaining: 1m 5s\n",
      "622:\tlearn: 0.0004255\ttotal: 1m 47s\tremaining: 1m 4s\n",
      "623:\tlearn: 0.0004253\ttotal: 1m 47s\tremaining: 1m 4s\n",
      "624:\tlearn: 0.0004252\ttotal: 1m 47s\tremaining: 1m 4s\n",
      "625:\tlearn: 0.0004252\ttotal: 1m 47s\tremaining: 1m 4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626:\tlearn: 0.0004251\ttotal: 1m 47s\tremaining: 1m 4s\n",
      "627:\tlearn: 0.0004252\ttotal: 1m 47s\tremaining: 1m 3s\n",
      "628:\tlearn: 0.0004252\ttotal: 1m 48s\tremaining: 1m 3s\n",
      "629:\tlearn: 0.0004252\ttotal: 1m 48s\tremaining: 1m 3s\n",
      "630:\tlearn: 0.0004250\ttotal: 1m 48s\tremaining: 1m 3s\n",
      "631:\tlearn: 0.0004250\ttotal: 1m 48s\tremaining: 1m 3s\n",
      "632:\tlearn: 0.0004250\ttotal: 1m 48s\tremaining: 1m 3s\n",
      "633:\tlearn: 0.0004250\ttotal: 1m 48s\tremaining: 1m 2s\n",
      "634:\tlearn: 0.0004249\ttotal: 1m 48s\tremaining: 1m 2s\n",
      "635:\tlearn: 0.0004248\ttotal: 1m 49s\tremaining: 1m 2s\n",
      "636:\tlearn: 0.0004247\ttotal: 1m 49s\tremaining: 1m 2s\n",
      "637:\tlearn: 0.0004247\ttotal: 1m 49s\tremaining: 1m 2s\n",
      "638:\tlearn: 0.0004247\ttotal: 1m 49s\tremaining: 1m 1s\n",
      "639:\tlearn: 0.0004246\ttotal: 1m 49s\tremaining: 1m 1s\n",
      "640:\tlearn: 0.0004246\ttotal: 1m 49s\tremaining: 1m 1s\n",
      "641:\tlearn: 0.0004246\ttotal: 1m 49s\tremaining: 1m 1s\n",
      "642:\tlearn: 0.0004246\ttotal: 1m 50s\tremaining: 1m 1s\n",
      "643:\tlearn: 0.0004244\ttotal: 1m 50s\tremaining: 1m\n",
      "644:\tlearn: 0.0004237\ttotal: 1m 50s\tremaining: 1m\n",
      "645:\tlearn: 0.0004237\ttotal: 1m 50s\tremaining: 1m\n",
      "646:\tlearn: 0.0004237\ttotal: 1m 50s\tremaining: 1m\n",
      "647:\tlearn: 0.0004235\ttotal: 1m 50s\tremaining: 1m\n",
      "648:\tlearn: 0.0004235\ttotal: 1m 51s\tremaining: 1m\n",
      "649:\tlearn: 0.0004235\ttotal: 1m 51s\tremaining: 59.9s\n",
      "650:\tlearn: 0.0004233\ttotal: 1m 51s\tremaining: 59.7s\n",
      "651:\tlearn: 0.0004232\ttotal: 1m 51s\tremaining: 59.5s\n",
      "652:\tlearn: 0.0004231\ttotal: 1m 51s\tremaining: 59.3s\n",
      "653:\tlearn: 0.0004231\ttotal: 1m 51s\tremaining: 59.1s\n",
      "654:\tlearn: 0.0004231\ttotal: 1m 51s\tremaining: 59s\n",
      "655:\tlearn: 0.0004231\ttotal: 1m 52s\tremaining: 58.8s\n",
      "656:\tlearn: 0.0004230\ttotal: 1m 52s\tremaining: 58.6s\n",
      "657:\tlearn: 0.0004229\ttotal: 1m 52s\tremaining: 58.4s\n",
      "658:\tlearn: 0.0004227\ttotal: 1m 52s\tremaining: 58.2s\n",
      "659:\tlearn: 0.0004227\ttotal: 1m 52s\tremaining: 58s\n",
      "660:\tlearn: 0.0004225\ttotal: 1m 52s\tremaining: 57.9s\n",
      "661:\tlearn: 0.0004225\ttotal: 1m 52s\tremaining: 57.7s\n",
      "662:\tlearn: 0.0004225\ttotal: 1m 53s\tremaining: 57.5s\n",
      "663:\tlearn: 0.0004224\ttotal: 1m 53s\tremaining: 57.3s\n",
      "664:\tlearn: 0.0004221\ttotal: 1m 53s\tremaining: 57.1s\n",
      "665:\tlearn: 0.0004220\ttotal: 1m 53s\tremaining: 57s\n",
      "666:\tlearn: 0.0004219\ttotal: 1m 53s\tremaining: 56.8s\n",
      "667:\tlearn: 0.0004218\ttotal: 1m 53s\tremaining: 56.6s\n",
      "668:\tlearn: 0.0004214\ttotal: 1m 54s\tremaining: 56.4s\n",
      "669:\tlearn: 0.0004213\ttotal: 1m 54s\tremaining: 56.2s\n",
      "670:\tlearn: 0.0004213\ttotal: 1m 54s\tremaining: 56.1s\n",
      "671:\tlearn: 0.0004212\ttotal: 1m 54s\tremaining: 55.9s\n",
      "672:\tlearn: 0.0004213\ttotal: 1m 54s\tremaining: 55.7s\n",
      "673:\tlearn: 0.0004211\ttotal: 1m 54s\tremaining: 55.5s\n",
      "674:\tlearn: 0.0004211\ttotal: 1m 54s\tremaining: 55.3s\n",
      "675:\tlearn: 0.0004211\ttotal: 1m 55s\tremaining: 55.1s\n",
      "676:\tlearn: 0.0004210\ttotal: 1m 55s\tremaining: 55s\n",
      "677:\tlearn: 0.0004210\ttotal: 1m 55s\tremaining: 54.8s\n",
      "678:\tlearn: 0.0004210\ttotal: 1m 55s\tremaining: 54.6s\n",
      "679:\tlearn: 0.0004210\ttotal: 1m 55s\tremaining: 54.4s\n",
      "680:\tlearn: 0.0004210\ttotal: 1m 55s\tremaining: 54.2s\n",
      "681:\tlearn: 0.0004209\ttotal: 1m 55s\tremaining: 54.1s\n",
      "682:\tlearn: 0.0004209\ttotal: 1m 56s\tremaining: 53.9s\n",
      "683:\tlearn: 0.0004207\ttotal: 1m 56s\tremaining: 53.7s\n",
      "684:\tlearn: 0.0004207\ttotal: 1m 56s\tremaining: 53.5s\n",
      "685:\tlearn: 0.0004207\ttotal: 1m 56s\tremaining: 53.3s\n",
      "686:\tlearn: 0.0004207\ttotal: 1m 56s\tremaining: 53.2s\n",
      "687:\tlearn: 0.0004207\ttotal: 1m 56s\tremaining: 53s\n",
      "688:\tlearn: 0.0004206\ttotal: 1m 56s\tremaining: 52.8s\n",
      "689:\tlearn: 0.0004203\ttotal: 1m 57s\tremaining: 52.6s\n",
      "690:\tlearn: 0.0004202\ttotal: 1m 57s\tremaining: 52.5s\n",
      "691:\tlearn: 0.0004201\ttotal: 1m 57s\tremaining: 52.3s\n",
      "692:\tlearn: 0.0004201\ttotal: 1m 57s\tremaining: 52.1s\n",
      "693:\tlearn: 0.0004201\ttotal: 1m 57s\tremaining: 51.9s\n",
      "694:\tlearn: 0.0004201\ttotal: 1m 57s\tremaining: 51.7s\n",
      "695:\tlearn: 0.0004199\ttotal: 1m 58s\tremaining: 51.6s\n",
      "696:\tlearn: 0.0004199\ttotal: 1m 58s\tremaining: 51.4s\n",
      "697:\tlearn: 0.0004198\ttotal: 1m 58s\tremaining: 51.2s\n",
      "698:\tlearn: 0.0004198\ttotal: 1m 58s\tremaining: 51s\n",
      "699:\tlearn: 0.0004198\ttotal: 1m 58s\tremaining: 50.8s\n",
      "700:\tlearn: 0.0004197\ttotal: 1m 58s\tremaining: 50.7s\n",
      "701:\tlearn: 0.0004197\ttotal: 1m 58s\tremaining: 50.5s\n",
      "702:\tlearn: 0.0004197\ttotal: 1m 59s\tremaining: 50.3s\n",
      "703:\tlearn: 0.0004196\ttotal: 1m 59s\tremaining: 50.1s\n",
      "704:\tlearn: 0.0004196\ttotal: 1m 59s\tremaining: 49.9s\n",
      "705:\tlearn: 0.0004195\ttotal: 1m 59s\tremaining: 49.8s\n",
      "706:\tlearn: 0.0004195\ttotal: 1m 59s\tremaining: 49.6s\n",
      "707:\tlearn: 0.0004195\ttotal: 1m 59s\tremaining: 49.4s\n",
      "708:\tlearn: 0.0004194\ttotal: 1m 59s\tremaining: 49.2s\n",
      "709:\tlearn: 0.0004193\ttotal: 2m\tremaining: 49.1s\n",
      "710:\tlearn: 0.0004193\ttotal: 2m\tremaining: 48.9s\n",
      "711:\tlearn: 0.0004193\ttotal: 2m\tremaining: 48.7s\n",
      "712:\tlearn: 0.0004193\ttotal: 2m\tremaining: 48.5s\n",
      "713:\tlearn: 0.0004193\ttotal: 2m\tremaining: 48.3s\n",
      "714:\tlearn: 0.0004191\ttotal: 2m\tremaining: 48.2s\n",
      "715:\tlearn: 0.0004190\ttotal: 2m\tremaining: 48s\n",
      "716:\tlearn: 0.0004189\ttotal: 2m 1s\tremaining: 47.8s\n",
      "717:\tlearn: 0.0004189\ttotal: 2m 1s\tremaining: 47.6s\n",
      "718:\tlearn: 0.0004189\ttotal: 2m 1s\tremaining: 47.5s\n",
      "719:\tlearn: 0.0004190\ttotal: 2m 1s\tremaining: 47.3s\n",
      "720:\tlearn: 0.0004189\ttotal: 2m 1s\tremaining: 47.1s\n",
      "721:\tlearn: 0.0004189\ttotal: 2m 1s\tremaining: 46.9s\n",
      "722:\tlearn: 0.0004184\ttotal: 2m 2s\tremaining: 46.8s\n",
      "723:\tlearn: 0.0004184\ttotal: 2m 2s\tremaining: 46.6s\n",
      "724:\tlearn: 0.0004184\ttotal: 2m 2s\tremaining: 46.4s\n",
      "725:\tlearn: 0.0004185\ttotal: 2m 2s\tremaining: 46.2s\n",
      "726:\tlearn: 0.0004181\ttotal: 2m 2s\tremaining: 46.1s\n",
      "727:\tlearn: 0.0004182\ttotal: 2m 2s\tremaining: 45.9s\n",
      "728:\tlearn: 0.0004180\ttotal: 2m 2s\tremaining: 45.7s\n",
      "729:\tlearn: 0.0004176\ttotal: 2m 3s\tremaining: 45.5s\n",
      "730:\tlearn: 0.0004177\ttotal: 2m 3s\tremaining: 45.4s\n",
      "731:\tlearn: 0.0004176\ttotal: 2m 3s\tremaining: 45.2s\n",
      "732:\tlearn: 0.0004173\ttotal: 2m 3s\tremaining: 45s\n",
      "733:\tlearn: 0.0004173\ttotal: 2m 3s\tremaining: 44.8s\n",
      "734:\tlearn: 0.0004173\ttotal: 2m 3s\tremaining: 44.7s\n",
      "735:\tlearn: 0.0004173\ttotal: 2m 4s\tremaining: 44.5s\n",
      "736:\tlearn: 0.0004172\ttotal: 2m 4s\tremaining: 44.3s\n",
      "737:\tlearn: 0.0004172\ttotal: 2m 4s\tremaining: 44.1s\n",
      "738:\tlearn: 0.0004172\ttotal: 2m 4s\tremaining: 44s\n",
      "739:\tlearn: 0.0004173\ttotal: 2m 4s\tremaining: 43.8s\n",
      "740:\tlearn: 0.0004173\ttotal: 2m 4s\tremaining: 43.6s\n",
      "741:\tlearn: 0.0004172\ttotal: 2m 4s\tremaining: 43.4s\n",
      "742:\tlearn: 0.0004172\ttotal: 2m 5s\tremaining: 43.3s\n",
      "743:\tlearn: 0.0004171\ttotal: 2m 5s\tremaining: 43.1s\n",
      "744:\tlearn: 0.0004173\ttotal: 2m 5s\tremaining: 42.9s\n",
      "745:\tlearn: 0.0004172\ttotal: 2m 5s\tremaining: 42.7s\n",
      "746:\tlearn: 0.0004172\ttotal: 2m 5s\tremaining: 42.5s\n",
      "747:\tlearn: 0.0004172\ttotal: 2m 5s\tremaining: 42.4s\n",
      "748:\tlearn: 0.0004172\ttotal: 2m 5s\tremaining: 42.2s\n",
      "749:\tlearn: 0.0004172\ttotal: 2m 6s\tremaining: 42s\n",
      "750:\tlearn: 0.0004171\ttotal: 2m 6s\tremaining: 41.8s\n",
      "751:\tlearn: 0.0004171\ttotal: 2m 6s\tremaining: 41.7s\n",
      "752:\tlearn: 0.0004169\ttotal: 2m 6s\tremaining: 41.5s\n",
      "753:\tlearn: 0.0004156\ttotal: 2m 6s\tremaining: 41.3s\n",
      "754:\tlearn: 0.0004156\ttotal: 2m 6s\tremaining: 41.2s\n",
      "755:\tlearn: 0.0004155\ttotal: 2m 6s\tremaining: 41s\n",
      "756:\tlearn: 0.0004156\ttotal: 2m 7s\tremaining: 40.8s\n",
      "757:\tlearn: 0.0004155\ttotal: 2m 7s\tremaining: 40.6s\n",
      "758:\tlearn: 0.0004155\ttotal: 2m 7s\tremaining: 40.5s\n",
      "759:\tlearn: 0.0004155\ttotal: 2m 7s\tremaining: 40.3s\n",
      "760:\tlearn: 0.0004155\ttotal: 2m 7s\tremaining: 40.1s\n",
      "761:\tlearn: 0.0004153\ttotal: 2m 7s\tremaining: 39.9s\n",
      "762:\tlearn: 0.0004153\ttotal: 2m 8s\tremaining: 39.8s\n",
      "763:\tlearn: 0.0004153\ttotal: 2m 8s\tremaining: 39.6s\n",
      "764:\tlearn: 0.0004153\ttotal: 2m 8s\tremaining: 39.4s\n",
      "765:\tlearn: 0.0004153\ttotal: 2m 8s\tremaining: 39.3s\n",
      "766:\tlearn: 0.0004147\ttotal: 2m 8s\tremaining: 39.1s\n",
      "767:\tlearn: 0.0004144\ttotal: 2m 8s\tremaining: 38.9s\n",
      "768:\tlearn: 0.0004144\ttotal: 2m 8s\tremaining: 38.7s\n",
      "769:\tlearn: 0.0004143\ttotal: 2m 9s\tremaining: 38.6s\n",
      "770:\tlearn: 0.0004143\ttotal: 2m 9s\tremaining: 38.4s\n",
      "771:\tlearn: 0.0004144\ttotal: 2m 9s\tremaining: 38.2s\n",
      "772:\tlearn: 0.0004144\ttotal: 2m 9s\tremaining: 38.1s\n",
      "773:\tlearn: 0.0004144\ttotal: 2m 9s\tremaining: 37.9s\n",
      "774:\tlearn: 0.0004144\ttotal: 2m 9s\tremaining: 37.7s\n",
      "775:\tlearn: 0.0004143\ttotal: 2m 9s\tremaining: 37.5s\n",
      "776:\tlearn: 0.0004141\ttotal: 2m 10s\tremaining: 37.4s\n",
      "777:\tlearn: 0.0004140\ttotal: 2m 10s\tremaining: 37.2s\n",
      "778:\tlearn: 0.0004140\ttotal: 2m 10s\tremaining: 37s\n",
      "779:\tlearn: 0.0004140\ttotal: 2m 10s\tremaining: 36.8s\n",
      "780:\tlearn: 0.0004139\ttotal: 2m 10s\tremaining: 36.7s\n",
      "781:\tlearn: 0.0004139\ttotal: 2m 10s\tremaining: 36.5s\n",
      "782:\tlearn: 0.0004139\ttotal: 2m 11s\tremaining: 36.3s\n",
      "783:\tlearn: 0.0004138\ttotal: 2m 11s\tremaining: 36.2s\n",
      "784:\tlearn: 0.0004138\ttotal: 2m 11s\tremaining: 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785:\tlearn: 0.0004137\ttotal: 2m 11s\tremaining: 35.8s\n",
      "786:\tlearn: 0.0004139\ttotal: 2m 11s\tremaining: 35.6s\n",
      "787:\tlearn: 0.0004135\ttotal: 2m 11s\tremaining: 35.5s\n",
      "788:\tlearn: 0.0004135\ttotal: 2m 12s\tremaining: 35.3s\n",
      "789:\tlearn: 0.0004134\ttotal: 2m 12s\tremaining: 35.1s\n",
      "790:\tlearn: 0.0004133\ttotal: 2m 12s\tremaining: 35s\n",
      "791:\tlearn: 0.0004129\ttotal: 2m 12s\tremaining: 34.8s\n",
      "792:\tlearn: 0.0004129\ttotal: 2m 12s\tremaining: 34.6s\n",
      "793:\tlearn: 0.0004129\ttotal: 2m 12s\tremaining: 34.4s\n",
      "794:\tlearn: 0.0004129\ttotal: 2m 12s\tremaining: 34.3s\n",
      "795:\tlearn: 0.0004127\ttotal: 2m 13s\tremaining: 34.1s\n",
      "796:\tlearn: 0.0004125\ttotal: 2m 13s\tremaining: 33.9s\n",
      "797:\tlearn: 0.0004125\ttotal: 2m 13s\tremaining: 33.8s\n",
      "798:\tlearn: 0.0004125\ttotal: 2m 13s\tremaining: 33.6s\n",
      "799:\tlearn: 0.0004125\ttotal: 2m 13s\tremaining: 33.4s\n",
      "800:\tlearn: 0.0004110\ttotal: 2m 13s\tremaining: 33.2s\n",
      "801:\tlearn: 0.0004111\ttotal: 2m 13s\tremaining: 33.1s\n",
      "802:\tlearn: 0.0004110\ttotal: 2m 14s\tremaining: 32.9s\n",
      "803:\tlearn: 0.0004109\ttotal: 2m 14s\tremaining: 32.7s\n",
      "804:\tlearn: 0.0004110\ttotal: 2m 14s\tremaining: 32.5s\n",
      "805:\tlearn: 0.0004110\ttotal: 2m 14s\tremaining: 32.4s\n",
      "806:\tlearn: 0.0004110\ttotal: 2m 14s\tremaining: 32.2s\n",
      "807:\tlearn: 0.0004110\ttotal: 2m 14s\tremaining: 32s\n",
      "808:\tlearn: 0.0004106\ttotal: 2m 14s\tremaining: 31.9s\n",
      "809:\tlearn: 0.0004105\ttotal: 2m 15s\tremaining: 31.7s\n",
      "810:\tlearn: 0.0004106\ttotal: 2m 15s\tremaining: 31.5s\n",
      "811:\tlearn: 0.0004105\ttotal: 2m 15s\tremaining: 31.3s\n",
      "812:\tlearn: 0.0004105\ttotal: 2m 15s\tremaining: 31.2s\n",
      "813:\tlearn: 0.0004098\ttotal: 2m 15s\tremaining: 31s\n",
      "814:\tlearn: 0.0004097\ttotal: 2m 15s\tremaining: 30.8s\n",
      "815:\tlearn: 0.0004097\ttotal: 2m 15s\tremaining: 30.7s\n",
      "816:\tlearn: 0.0004096\ttotal: 2m 16s\tremaining: 30.5s\n",
      "817:\tlearn: 0.0004096\ttotal: 2m 16s\tremaining: 30.3s\n",
      "818:\tlearn: 0.0004096\ttotal: 2m 16s\tremaining: 30.1s\n",
      "819:\tlearn: 0.0004096\ttotal: 2m 16s\tremaining: 30s\n",
      "820:\tlearn: 0.0004095\ttotal: 2m 16s\tremaining: 29.8s\n",
      "821:\tlearn: 0.0004094\ttotal: 2m 16s\tremaining: 29.6s\n",
      "822:\tlearn: 0.0004094\ttotal: 2m 16s\tremaining: 29.5s\n",
      "823:\tlearn: 0.0004094\ttotal: 2m 17s\tremaining: 29.3s\n",
      "824:\tlearn: 0.0004094\ttotal: 2m 17s\tremaining: 29.1s\n",
      "825:\tlearn: 0.0004093\ttotal: 2m 17s\tremaining: 28.9s\n",
      "826:\tlearn: 0.0004092\ttotal: 2m 17s\tremaining: 28.8s\n",
      "827:\tlearn: 0.0004092\ttotal: 2m 17s\tremaining: 28.6s\n",
      "828:\tlearn: 0.0004092\ttotal: 2m 17s\tremaining: 28.4s\n",
      "829:\tlearn: 0.0004092\ttotal: 2m 17s\tremaining: 28.3s\n",
      "830:\tlearn: 0.0004091\ttotal: 2m 18s\tremaining: 28.1s\n",
      "831:\tlearn: 0.0004091\ttotal: 2m 18s\tremaining: 27.9s\n",
      "832:\tlearn: 0.0004091\ttotal: 2m 18s\tremaining: 27.7s\n",
      "833:\tlearn: 0.0004090\ttotal: 2m 18s\tremaining: 27.6s\n",
      "834:\tlearn: 0.0004089\ttotal: 2m 18s\tremaining: 27.4s\n",
      "835:\tlearn: 0.0004090\ttotal: 2m 18s\tremaining: 27.2s\n",
      "836:\tlearn: 0.0004089\ttotal: 2m 19s\tremaining: 27.1s\n",
      "837:\tlearn: 0.0004089\ttotal: 2m 19s\tremaining: 26.9s\n",
      "838:\tlearn: 0.0004088\ttotal: 2m 19s\tremaining: 26.7s\n",
      "839:\tlearn: 0.0004087\ttotal: 2m 19s\tremaining: 26.6s\n",
      "840:\tlearn: 0.0004086\ttotal: 2m 19s\tremaining: 26.4s\n",
      "841:\tlearn: 0.0004086\ttotal: 2m 19s\tremaining: 26.2s\n",
      "842:\tlearn: 0.0004080\ttotal: 2m 19s\tremaining: 26s\n",
      "843:\tlearn: 0.0004079\ttotal: 2m 20s\tremaining: 25.9s\n",
      "844:\tlearn: 0.0004078\ttotal: 2m 20s\tremaining: 25.7s\n",
      "845:\tlearn: 0.0004078\ttotal: 2m 20s\tremaining: 25.5s\n",
      "846:\tlearn: 0.0004078\ttotal: 2m 20s\tremaining: 25.4s\n",
      "847:\tlearn: 0.0004079\ttotal: 2m 20s\tremaining: 25.2s\n",
      "848:\tlearn: 0.0004078\ttotal: 2m 20s\tremaining: 25s\n",
      "849:\tlearn: 0.0004069\ttotal: 2m 20s\tremaining: 24.9s\n",
      "850:\tlearn: 0.0004069\ttotal: 2m 21s\tremaining: 24.7s\n",
      "851:\tlearn: 0.0004068\ttotal: 2m 21s\tremaining: 24.5s\n",
      "852:\tlearn: 0.0004069\ttotal: 2m 21s\tremaining: 24.4s\n",
      "853:\tlearn: 0.0004068\ttotal: 2m 21s\tremaining: 24.2s\n",
      "854:\tlearn: 0.0004068\ttotal: 2m 21s\tremaining: 24s\n",
      "855:\tlearn: 0.0004068\ttotal: 2m 21s\tremaining: 23.9s\n",
      "856:\tlearn: 0.0004069\ttotal: 2m 21s\tremaining: 23.7s\n",
      "857:\tlearn: 0.0004068\ttotal: 2m 22s\tremaining: 23.5s\n",
      "858:\tlearn: 0.0004065\ttotal: 2m 22s\tremaining: 23.4s\n",
      "859:\tlearn: 0.0004064\ttotal: 2m 22s\tremaining: 23.2s\n",
      "860:\tlearn: 0.0004064\ttotal: 2m 22s\tremaining: 23s\n",
      "861:\tlearn: 0.0004064\ttotal: 2m 22s\tremaining: 22.9s\n",
      "862:\tlearn: 0.0004064\ttotal: 2m 22s\tremaining: 22.7s\n",
      "863:\tlearn: 0.0004063\ttotal: 2m 23s\tremaining: 22.5s\n",
      "864:\tlearn: 0.0004063\ttotal: 2m 23s\tremaining: 22.3s\n",
      "865:\tlearn: 0.0004060\ttotal: 2m 23s\tremaining: 22.2s\n",
      "866:\tlearn: 0.0004059\ttotal: 2m 23s\tremaining: 22s\n",
      "867:\tlearn: 0.0004059\ttotal: 2m 23s\tremaining: 21.8s\n",
      "868:\tlearn: 0.0004059\ttotal: 2m 23s\tremaining: 21.7s\n",
      "869:\tlearn: 0.0004059\ttotal: 2m 23s\tremaining: 21.5s\n",
      "870:\tlearn: 0.0004059\ttotal: 2m 24s\tremaining: 21.3s\n",
      "871:\tlearn: 0.0004058\ttotal: 2m 24s\tremaining: 21.2s\n",
      "872:\tlearn: 0.0004058\ttotal: 2m 24s\tremaining: 21s\n",
      "873:\tlearn: 0.0004057\ttotal: 2m 24s\tremaining: 20.8s\n",
      "874:\tlearn: 0.0004057\ttotal: 2m 24s\tremaining: 20.7s\n",
      "875:\tlearn: 0.0004057\ttotal: 2m 24s\tremaining: 20.5s\n",
      "876:\tlearn: 0.0004057\ttotal: 2m 24s\tremaining: 20.3s\n",
      "877:\tlearn: 0.0004057\ttotal: 2m 25s\tremaining: 20.2s\n",
      "878:\tlearn: 0.0004056\ttotal: 2m 25s\tremaining: 20s\n",
      "879:\tlearn: 0.0004057\ttotal: 2m 25s\tremaining: 19.8s\n",
      "880:\tlearn: 0.0004056\ttotal: 2m 25s\tremaining: 19.7s\n",
      "881:\tlearn: 0.0004053\ttotal: 2m 25s\tremaining: 19.5s\n",
      "882:\tlearn: 0.0004052\ttotal: 2m 25s\tremaining: 19.3s\n",
      "883:\tlearn: 0.0004052\ttotal: 2m 25s\tremaining: 19.2s\n",
      "884:\tlearn: 0.0004050\ttotal: 2m 26s\tremaining: 19s\n",
      "885:\tlearn: 0.0004050\ttotal: 2m 26s\tremaining: 18.8s\n",
      "886:\tlearn: 0.0004043\ttotal: 2m 26s\tremaining: 18.7s\n",
      "887:\tlearn: 0.0004044\ttotal: 2m 26s\tremaining: 18.5s\n",
      "888:\tlearn: 0.0004043\ttotal: 2m 26s\tremaining: 18.3s\n",
      "889:\tlearn: 0.0004042\ttotal: 2m 26s\tremaining: 18.2s\n",
      "890:\tlearn: 0.0004042\ttotal: 2m 27s\tremaining: 18s\n",
      "891:\tlearn: 0.0004042\ttotal: 2m 27s\tremaining: 17.8s\n",
      "892:\tlearn: 0.0004041\ttotal: 2m 27s\tremaining: 17.7s\n",
      "893:\tlearn: 0.0004036\ttotal: 2m 27s\tremaining: 17.5s\n",
      "894:\tlearn: 0.0004035\ttotal: 2m 27s\tremaining: 17.3s\n",
      "895:\tlearn: 0.0004035\ttotal: 2m 27s\tremaining: 17.2s\n",
      "896:\tlearn: 0.0004035\ttotal: 2m 27s\tremaining: 17s\n",
      "897:\tlearn: 0.0004035\ttotal: 2m 28s\tremaining: 16.8s\n",
      "898:\tlearn: 0.0004032\ttotal: 2m 28s\tremaining: 16.7s\n",
      "899:\tlearn: 0.0004031\ttotal: 2m 28s\tremaining: 16.5s\n",
      "900:\tlearn: 0.0004032\ttotal: 2m 28s\tremaining: 16.3s\n",
      "901:\tlearn: 0.0004032\ttotal: 2m 28s\tremaining: 16.2s\n",
      "902:\tlearn: 0.0004031\ttotal: 2m 28s\tremaining: 16s\n",
      "903:\tlearn: 0.0004031\ttotal: 2m 28s\tremaining: 15.8s\n",
      "904:\tlearn: 0.0004031\ttotal: 2m 29s\tremaining: 15.7s\n",
      "905:\tlearn: 0.0004030\ttotal: 2m 29s\tremaining: 15.5s\n",
      "906:\tlearn: 0.0004030\ttotal: 2m 29s\tremaining: 15.3s\n",
      "907:\tlearn: 0.0004030\ttotal: 2m 29s\tremaining: 15.2s\n",
      "908:\tlearn: 0.0004030\ttotal: 2m 29s\tremaining: 15s\n",
      "909:\tlearn: 0.0004030\ttotal: 2m 29s\tremaining: 14.8s\n",
      "910:\tlearn: 0.0004030\ttotal: 2m 29s\tremaining: 14.7s\n",
      "911:\tlearn: 0.0004029\ttotal: 2m 30s\tremaining: 14.5s\n",
      "912:\tlearn: 0.0004029\ttotal: 2m 30s\tremaining: 14.3s\n",
      "913:\tlearn: 0.0004028\ttotal: 2m 30s\tremaining: 14.2s\n",
      "914:\tlearn: 0.0004028\ttotal: 2m 30s\tremaining: 14s\n",
      "915:\tlearn: 0.0004027\ttotal: 2m 30s\tremaining: 13.8s\n",
      "916:\tlearn: 0.0004026\ttotal: 2m 30s\tremaining: 13.7s\n",
      "917:\tlearn: 0.0004026\ttotal: 2m 30s\tremaining: 13.5s\n",
      "918:\tlearn: 0.0004026\ttotal: 2m 31s\tremaining: 13.3s\n",
      "919:\tlearn: 0.0004014\ttotal: 2m 31s\tremaining: 13.2s\n",
      "920:\tlearn: 0.0004013\ttotal: 2m 31s\tremaining: 13s\n",
      "921:\tlearn: 0.0004013\ttotal: 2m 31s\tremaining: 12.8s\n",
      "922:\tlearn: 0.0004013\ttotal: 2m 31s\tremaining: 12.7s\n",
      "923:\tlearn: 0.0004013\ttotal: 2m 31s\tremaining: 12.5s\n",
      "924:\tlearn: 0.0004013\ttotal: 2m 32s\tremaining: 12.3s\n",
      "925:\tlearn: 0.0004009\ttotal: 2m 32s\tremaining: 12.2s\n",
      "926:\tlearn: 0.0004009\ttotal: 2m 32s\tremaining: 12s\n",
      "927:\tlearn: 0.0004009\ttotal: 2m 32s\tremaining: 11.8s\n",
      "928:\tlearn: 0.0004010\ttotal: 2m 32s\tremaining: 11.7s\n",
      "929:\tlearn: 0.0004009\ttotal: 2m 32s\tremaining: 11.5s\n",
      "930:\tlearn: 0.0004008\ttotal: 2m 32s\tremaining: 11.3s\n",
      "931:\tlearn: 0.0004008\ttotal: 2m 33s\tremaining: 11.2s\n",
      "932:\tlearn: 0.0004009\ttotal: 2m 33s\tremaining: 11s\n",
      "933:\tlearn: 0.0004008\ttotal: 2m 33s\tremaining: 10.8s\n",
      "934:\tlearn: 0.0004008\ttotal: 2m 33s\tremaining: 10.7s\n",
      "935:\tlearn: 0.0003998\ttotal: 2m 33s\tremaining: 10.5s\n",
      "936:\tlearn: 0.0003998\ttotal: 2m 33s\tremaining: 10.3s\n",
      "937:\tlearn: 0.0003997\ttotal: 2m 34s\tremaining: 10.2s\n",
      "938:\tlearn: 0.0003995\ttotal: 2m 34s\tremaining: 10s\n",
      "939:\tlearn: 0.0003995\ttotal: 2m 34s\tremaining: 9.85s\n",
      "940:\tlearn: 0.0003994\ttotal: 2m 34s\tremaining: 9.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941:\tlearn: 0.0003994\ttotal: 2m 34s\tremaining: 9.52s\n",
      "942:\tlearn: 0.0003989\ttotal: 2m 34s\tremaining: 9.35s\n",
      "943:\tlearn: 0.0003989\ttotal: 2m 34s\tremaining: 9.19s\n",
      "944:\tlearn: 0.0003988\ttotal: 2m 35s\tremaining: 9.02s\n",
      "945:\tlearn: 0.0003987\ttotal: 2m 35s\tremaining: 8.86s\n",
      "946:\tlearn: 0.0003987\ttotal: 2m 35s\tremaining: 8.69s\n",
      "947:\tlearn: 0.0003987\ttotal: 2m 35s\tremaining: 8.53s\n",
      "948:\tlearn: 0.0003987\ttotal: 2m 35s\tremaining: 8.36s\n",
      "949:\tlearn: 0.0003986\ttotal: 2m 35s\tremaining: 8.2s\n",
      "950:\tlearn: 0.0003986\ttotal: 2m 35s\tremaining: 8.03s\n",
      "951:\tlearn: 0.0003986\ttotal: 2m 36s\tremaining: 7.87s\n",
      "952:\tlearn: 0.0003985\ttotal: 2m 36s\tremaining: 7.7s\n",
      "953:\tlearn: 0.0003985\ttotal: 2m 36s\tremaining: 7.54s\n",
      "954:\tlearn: 0.0003982\ttotal: 2m 36s\tremaining: 7.38s\n",
      "955:\tlearn: 0.0003982\ttotal: 2m 36s\tremaining: 7.21s\n",
      "956:\tlearn: 0.0003981\ttotal: 2m 36s\tremaining: 7.04s\n",
      "957:\tlearn: 0.0003981\ttotal: 2m 36s\tremaining: 6.88s\n",
      "958:\tlearn: 0.0003981\ttotal: 2m 37s\tremaining: 6.72s\n",
      "959:\tlearn: 0.0003981\ttotal: 2m 37s\tremaining: 6.55s\n",
      "960:\tlearn: 0.0003979\ttotal: 2m 37s\tremaining: 6.39s\n",
      "961:\tlearn: 0.0003979\ttotal: 2m 37s\tremaining: 6.22s\n",
      "962:\tlearn: 0.0003979\ttotal: 2m 37s\tremaining: 6.06s\n",
      "963:\tlearn: 0.0003979\ttotal: 2m 37s\tremaining: 5.89s\n",
      "964:\tlearn: 0.0003978\ttotal: 2m 37s\tremaining: 5.73s\n",
      "965:\tlearn: 0.0003978\ttotal: 2m 38s\tremaining: 5.57s\n",
      "966:\tlearn: 0.0003978\ttotal: 2m 38s\tremaining: 5.4s\n",
      "967:\tlearn: 0.0003977\ttotal: 2m 38s\tremaining: 5.24s\n",
      "968:\tlearn: 0.0003977\ttotal: 2m 38s\tremaining: 5.07s\n",
      "969:\tlearn: 0.0003977\ttotal: 2m 38s\tremaining: 4.91s\n",
      "970:\tlearn: 0.0003976\ttotal: 2m 38s\tremaining: 4.74s\n",
      "971:\tlearn: 0.0003977\ttotal: 2m 38s\tremaining: 4.58s\n",
      "972:\tlearn: 0.0003976\ttotal: 2m 39s\tremaining: 4.42s\n",
      "973:\tlearn: 0.0003976\ttotal: 2m 39s\tremaining: 4.25s\n",
      "974:\tlearn: 0.0003976\ttotal: 2m 39s\tremaining: 4.09s\n",
      "975:\tlearn: 0.0003976\ttotal: 2m 39s\tremaining: 3.92s\n",
      "976:\tlearn: 0.0003976\ttotal: 2m 39s\tremaining: 3.76s\n",
      "977:\tlearn: 0.0003976\ttotal: 2m 39s\tremaining: 3.6s\n",
      "978:\tlearn: 0.0003976\ttotal: 2m 40s\tremaining: 3.43s\n",
      "979:\tlearn: 0.0003976\ttotal: 2m 40s\tremaining: 3.27s\n",
      "980:\tlearn: 0.0003975\ttotal: 2m 40s\tremaining: 3.1s\n",
      "981:\tlearn: 0.0003975\ttotal: 2m 40s\tremaining: 2.94s\n",
      "982:\tlearn: 0.0003975\ttotal: 2m 40s\tremaining: 2.78s\n",
      "983:\tlearn: 0.0003974\ttotal: 2m 40s\tremaining: 2.61s\n",
      "984:\tlearn: 0.0003970\ttotal: 2m 40s\tremaining: 2.45s\n",
      "985:\tlearn: 0.0003970\ttotal: 2m 41s\tremaining: 2.29s\n",
      "986:\tlearn: 0.0003969\ttotal: 2m 41s\tremaining: 2.12s\n",
      "987:\tlearn: 0.0003969\ttotal: 2m 41s\tremaining: 1.96s\n",
      "988:\tlearn: 0.0003969\ttotal: 2m 41s\tremaining: 1.8s\n",
      "989:\tlearn: 0.0003969\ttotal: 2m 41s\tremaining: 1.63s\n",
      "990:\tlearn: 0.0003969\ttotal: 2m 41s\tremaining: 1.47s\n",
      "991:\tlearn: 0.0003969\ttotal: 2m 41s\tremaining: 1.3s\n",
      "992:\tlearn: 0.0003965\ttotal: 2m 42s\tremaining: 1.14s\n",
      "993:\tlearn: 0.0003965\ttotal: 2m 42s\tremaining: 979ms\n",
      "994:\tlearn: 0.0003957\ttotal: 2m 42s\tremaining: 816ms\n",
      "995:\tlearn: 0.0003958\ttotal: 2m 42s\tremaining: 653ms\n",
      "996:\tlearn: 0.0003957\ttotal: 2m 42s\tremaining: 489ms\n",
      "997:\tlearn: 0.0003957\ttotal: 2m 42s\tremaining: 326ms\n",
      "998:\tlearn: 0.0003957\ttotal: 2m 42s\tremaining: 163ms\n",
      "999:\tlearn: 0.0003957\ttotal: 2m 43s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f0ec30b68d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# cbmodel = CatBoostClassifier(task_type = \"GPU\")\n",
    "# cbmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbmodel = joblib.load(JOBLIB_DIR + 'cbmodel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(cbmodel, JOBLIB_DIR + 'cbmodel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "\n",
    "# d_train = lgb.Dataset(X_train, label=y_train)\n",
    "# lgbmodel = lgb.train({'device': 'gpu'}, d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmodel = joblib.load(JOBLIB_DIR + 'lgbmodel.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(lgbmodel, JOBLIB_DIR + 'lgbmodel.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict value for the test data from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_preds = xgbmodel.predict(X_test)\n",
    "xgb_pred_prob = xgbmodel.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_preds = cbmodel.predict(X_test).astype(int)\n",
    "cb_pred_prob = cbmodel.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_pred_prob = lgbmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_preds = list()\n",
    "for i in range(0, len(lgb_pred_prob)):\n",
    "    if lgb_pred_prob[i] >= 0.5:\n",
    "        lgb_preds.append(1)\n",
    "    else:\n",
    "        lgb_preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    236528\n",
      "           1       1.00      1.00      1.00    190784\n",
      "\n",
      "    accuracy                           1.00    427312\n",
      "   macro avg       1.00      1.00      1.00    427312\n",
      "weighted avg       1.00      1.00      1.00    427312\n",
      "\n",
      "Accuracy Score: 0.999831504848916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[236521,      7],\n",
       "       [    65, 190719]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, xgb_preds))\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, xgb_preds))\n",
    "\n",
    "xgb_cm = confusion_matrix(y_test, xgb_preds)\n",
    "xgb_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_cm = pd.DataFrame(xgb_cm)\n",
    "# plt.figure(figsize = (8,6))\n",
    "# sn.heatmap(xgb_cm, cmap=\"Blues\")\n",
    "# plt.savefig('xgb_cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    236528\n",
      "           1       1.00      1.00      1.00    190784\n",
      "\n",
      "    accuracy                           1.00    427312\n",
      "   macro avg       1.00      1.00      1.00    427312\n",
      "weighted avg       1.00      1.00      1.00    427312\n",
      "\n",
      "Accuracy Score: 0.9998338450593477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[236519,      9],\n",
       "       [    62, 190722]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, cb_preds))\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, cb_preds))\n",
    "\n",
    "cb_cm = confusion_matrix(y_test, cb_preds)\n",
    "cb_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_cm = pd.DataFrame(cb_cm)\n",
    "# plt.figure(figsize = (8,6))\n",
    "# sn.heatmap(cb_cm, cmap=\"Blues\")\n",
    "# plt.savefig('cb_cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    236528\n",
      "           1       1.00      1.00      1.00    190784\n",
      "\n",
      "    accuracy                           1.00    427312\n",
      "   macro avg       1.00      1.00      1.00    427312\n",
      "weighted avg       1.00      1.00      1.00    427312\n",
      "\n",
      "Accuracy Score: 0.9997683191672595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[236500,     28],\n",
       "       [    71, 190713]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, lgb_preds))\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, lgb_preds))\n",
    "\n",
    "lgb_cm = confusion_matrix(y_test, lgb_preds)\n",
    "lgb_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_cm = pd.DataFrame(lgb_cm)\n",
    "# plt.figure(figsize = (8,6))\n",
    "# sn.heatmap(lgb_cm, cmap=\"Blues\")\n",
    "# plt.savefig('lgb_cm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for ensmeble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df = pd.DataFrame(list(zip(xgb_pred_prob[:, 1], cb_pred_prob[:, 1], lgb_pred_prob)), index=X_test.index, columns=['xgb_preds', 'cb_preds', 'lgb_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_df['actual'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb_preds</th>\n",
       "      <th>cb_preds</th>\n",
       "      <th>lgb_preds</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>922070</td>\n",
       "      <td>6.937559e-09</td>\n",
       "      <td>6.214033e-07</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5701</td>\n",
       "      <td>2.308788e-09</td>\n",
       "      <td>9.959800e-07</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1053606</td>\n",
       "      <td>1.853728e-07</td>\n",
       "      <td>3.656039e-07</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505344</td>\n",
       "      <td>9.999211e-01</td>\n",
       "      <td>9.999844e-01</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>788600</td>\n",
       "      <td>9.999812e-01</td>\n",
       "      <td>9.999893e-01</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296554</td>\n",
       "      <td>6.482034e-07</td>\n",
       "      <td>4.311466e-06</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>533765</td>\n",
       "      <td>9.999999e-01</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1231748</td>\n",
       "      <td>5.817403e-09</td>\n",
       "      <td>5.253834e-06</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125628</td>\n",
       "      <td>5.563496e-11</td>\n",
       "      <td>5.398879e-06</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275957</td>\n",
       "      <td>9.999969e-01</td>\n",
       "      <td>9.999995e-01</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427312 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            xgb_preds      cb_preds  lgb_preds  actual\n",
       "922070   6.937559e-09  6.214033e-07   0.000022       0\n",
       "5701     2.308788e-09  9.959800e-07   0.000174       0\n",
       "1053606  1.853728e-07  3.656039e-07  -0.000290       0\n",
       "505344   9.999211e-01  9.999844e-01   0.999329       1\n",
       "788600   9.999812e-01  9.999893e-01   0.999687       1\n",
       "...               ...           ...        ...     ...\n",
       "296554   6.482034e-07  4.311466e-06   0.000252       0\n",
       "533765   9.999999e-01  9.999995e-01   0.999912       1\n",
       "1231748  5.817403e-09  5.253834e-06   0.000072       0\n",
       "125628   5.563496e-11  5.398879e-06  -0.000418       0\n",
       "1275957  9.999969e-01  9.999995e-01   0.999843       1\n",
       "\n",
       "[427312 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_en, X_test_en, y_train_en, y_test_en = train_test_split(ensemble_df[['xgb_preds','cb_preds','lgb_preds']], ensemble_df['actual'], test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train (213656, 3)\n",
      "X Test (213656, 3)\n",
      "Y Train (213656,)\n",
      "Y Test (213656,)\n"
     ]
    }
   ],
   "source": [
    "print('X Train', X_train_en.shape)\n",
    "print('X Test', X_test_en.shape)\n",
    "print('Y Train', y_train_en.shape)\n",
    "print('Y Test', y_test_en.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model for finding the weights for each model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sourish/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train_en, y_train_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(JOBLIB_DIR + 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joblibs/model.joblib']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, JOBLIB_DIR + 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.98224112, 7.14086449, 5.47957222]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_en = model.predict(ensemble_df[['xgb_preds','cb_preds','lgb_preds']])\n",
    "y_pred_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    236528\n",
      "           1       1.00      1.00      1.00    190784\n",
      "\n",
      "    accuracy                           1.00    427312\n",
      "   macro avg       1.00      1.00      1.00    427312\n",
      "weighted avg       1.00      1.00      1.00    427312\n",
      "\n",
      "Accuracy Score: 0.9998595873740966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[236522,      6],\n",
       "       [    54, 190730]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(ensemble_df['actual'], y_pred_en))\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(ensemble_df['actual'], y_pred_en))\n",
    "\n",
    "cm = confusion_matrix(ensemble_df['actual'], y_pred_en)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = pd.DataFrame(cm)\n",
    "# plt.figure(figsize = (8,6))\n",
    "# sn.heatmap(cm, cmap=\"Blues\")\n",
    "# plt.savefig('cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = ['XGB', 'CB', 'LGB', 'Ensemble']\n",
    "label = [xgb_cm[1][0], cb_cm[1][0], lgb_cm[1][0], cm[1][0]]\n",
    "plt.bar(index, label)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('No of False Negative')\n",
    "plt.xticks(index, rotation=30)\n",
    "# plt.figure(figsize = (15,12))\n",
    "# plt.title('Market Share for Each Genre 1995-2017')\n",
    "# plt.savefig('fn_result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
